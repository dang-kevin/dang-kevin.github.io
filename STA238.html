<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>STA238: Probability, Statistics and Data Analysis II</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Kevin Dang</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-university"></span>
     
    Teaching
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="CHL5202.html">
        <span class="fa fa-book"></span>
         
        CHL5202 - Winter 2022
      </a>
    </li>
    <li>
      <a href="STA238.html">
        <span class="fa fa-book"></span>
         
        STA238 - Winter 2022
      </a>
    </li>
    <li>
      <a href="STA237.html">
        <span class="fa fa-book"></span>
         
        STA237 - Fall 2021
      </a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-project-diagram"></span>
     
    Projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="cognitive.html">
        <span class="fa fa-code"></span>
         
        Cognitive Flexibility
      </a>
    </li>
    <li>
      <a href="EDA.html">
        <span class="fa fa-code"></span>
         
        Exploratory Data Analysis
      </a>
    </li>
    <li>
      <a href="heart.html">
        <span class="fa fa-code"></span>
         
        Heart Disease Classifier
      </a>
    </li>
    <li>
      <a href="mice.html">
        <span class="fa fa-code"></span>
         
        Mice Protein Expression
      </a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-user"></span>
     
    About Me
  </a>
</li>
<li>
  <a href="files/Resume_Kevin_Dang.pdf">
    <span class="fa fa-file-pdf-o"></span>
     
    Resume
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">STA238: Probability, Statistics and Data Analysis II</h1>

</div>


<div id="course-description" class="section level1 unlisted unnumbered">
<h1 class="unlisted unnumbered">Course Description</h1>
<p>An introduction to statistical inference and practice. Statistical models and parameters, estimators of parameters and their statistical properties, methods of estimation, confidence intervals, hypothesis testing, likelihood function, the linear model. Use of statistical computation for data analysis and simulation.</p>
<p>Course material provided by Professor Karen Huynh Wong and modifications were made by myself.</p>
</div>
<div id="lab-0" class="section level1">
<h1>Lab 0</h1>
<p>In this R Lab, you will be guided by your TA to familiarize yourself with the R environment, using and formatting in R Markdown, and producing well-organized outputs.</p>
<div id="r-lab-learning-goals" class="section level2">
<h2>R Lab Learning Goals</h2>
<ul>
<li>Install and load packages in R, use them in an R Markdown file</li>
<li>Simple computations and referring to <code>?command_name</code> to find the documentation of various commands</li>
<li>Select elements, columns, or rows from a dataset</li>
<li>Produce simple plots in ggplot with informative and clearly formatted titles + labels</li>
<li>Use LaTeX notation to neatly and correctly display math notation. You can knit this document as you type (which also helps you identify bugs in your code!) to see how the format of the text translates into the finished product, such as creating headers, bold-facing, and math notation!</li>
<li>Knit your document to a finished document that includes written text and properly rendered math notation, with plots and source code separately embedded</li>
</ul>
<p>Some additional resources you may find helpful as you learn is the <a href="https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf">R Markdown Cheatsheet</a> and the <a href="http://tug.ctan.org/info/undergradmath/undergradmath.pdf">LaTeX Cheatsheet</a>. As you work more in LaTeX, the notation will get easier and become second nature!</p>
</div>
<div id="install-and-load-packages" class="section level2">
<h2>1. Install and Load Packages</h2>
<p>R packages are a collection of functions, code, and data sets that are developed by others and can be used to supplement the basic tools in R. R comes with some basic packages, but working with them can be sometimes clunky. You’ll begin by learning how to install packages and load packages, and the difference between these two actions!</p>
<p>Begin by installing and loading the <code>tidyverse</code> package, which is a collection of R packages. We will use this extensively in our course, as all packages within share similar structure and design, making it a very intuitive and versatile tool to master!</p>
<p><strong>Note: Never include a package install in your R chunks in an R Markdown file. R will not be able to knit your document! Instead, run it strictly within your console.</strong></p>
<pre class="r"><code># Students: What do you think the &#39;message = F&#39; in the R chunk option does? 
# Try knitting your document with and without the option

# Can also try `warning = F` to hide warnings
# echo = F` to run the chunk but hide the code

# install.packages(&quot;tidyverse&quot;)
library(tidyverse)

# Use Ctrl + Alt + I shortcut for creating code chunks</code></pre>
</div>
<div id="loading-data-and-saving-it-to-an-object" class="section level2">
<h2>2. Loading Data and Saving it to an Object</h2>
<p>Let’s examine some datasets that are already available in R (see <code>library(help = "datasets")</code> for a list of datasets in base R), starting with the ToothGrowth dataset.</p>
<pre class="r"><code># ?ToothGrowth

# Variable Assignment
dat &lt;- ToothGrowth

# Mostly useful for smaller datasets, but for larger ones we prefer to use glimpse and summary
# View(dat)

glimpse(dat)</code></pre>
<pre><code>## Rows: 60
## Columns: 3
## $ len  &lt;dbl&gt; 4.2, 11.5, 7.3, 5.8, 6.4, 10.0, 11.2, 11.2, 5.2, 7.0, 16.5, 16.5,~
## $ supp &lt;fct&gt; VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, V~
## $ dose &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, ~</code></pre>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##       len        supp         dose      
##  Min.   : 4.20   OJ:30   Min.   :0.500  
##  1st Qu.:13.07   VC:30   1st Qu.:0.500  
##  Median :19.25           Median :1.000  
##  Mean   :18.81           Mean   :1.167  
##  3rd Qu.:25.27           3rd Qu.:2.000  
##  Max.   :33.90           Max.   :2.000</code></pre>
</div>
<div id="simple-data-filtration" class="section level2">
<h2>3. Simple Data Filtration</h2>
<p>It looks like there are two groups of data in the <code>ToothGrowth</code> data set. What are they?</p>
<p>What if you only want to study the growth based on one source of vitamin C? How do you go about extracting this information?</p>
<pre class="r"><code># After loading and examining your data, and learning about selecting columns or elements
# from your data set, consider the following two commands below. 
# Briefly comment below what these two commands do:

# What does
which(dat$supp == &#39;VC&#39;) #do?
# Extracts which indices are TRUE</code></pre>
<pre class="r"><code># What does 
dat[dat$supp==&#39;VC&#39;, 1] #do?
# extracts the `len` variable/column, where `supp` is &#39;VC&#39;

# Alternative 1
# Pipe operator shortcut: Ctrl + Shift + M
dat %&gt;% 
  filter(supp == &quot;VC&quot;) %&gt;% 
  select(len)

# Alternative 2
# This is basically Alternative 1 without the pipe operator
select(filter(dat, supp == &quot;VC&quot;), len)</code></pre>
<pre class="r"><code># Below we can also extract the other 2 columns
dat[dat$supp==&#39;VC&#39;, 2]
dat[dat$supp==&#39;VC&#39;, 3]</code></pre>
</div>
<div id="formulating-a-question" class="section level2">
<h2>4. Formulating a Question</h2>
<p>After examining the data set, what are some study questions we can ask? Make some suggestions in the Teams chat!</p>
<p>Below are some questions suggested by students in the chat: * Does dosage and length have a positive correlation? * Which vitamin contributes to the most growth?</p>
</div>
<div id="calculations-in-r" class="section level2">
<h2>5. Calculations in R</h2>
<p>Find the (sample) mean and standard deviation of tooth length in the Vitamin C group and again in the group that only received Orange Juice. What can be said based on the numbers computed about the differences between the two groups?</p>
<p>Do this using the formula, instead of the functions <code>mean()</code> or <code>sd()</code> to practice using R as a calculator!</p>
<pre class="r"><code># Task for students: try to recreate the mean and variance values through
# Calculations in R, and compare them with the values you should get through
# mean() and sd() commands in R

# Create tooth length variable for the vitamin C 
vc &lt;- dat[dat$supp==&#39;VC&#39;, 1]

# take the sum of the tooth length, then divide by the number of values
n &lt;- length(vc)
mean.vc &lt;- sum(vc)/n
mean.vc</code></pre>
<pre><code>## [1] 16.96333</code></pre>
<pre class="r"><code># Can also compute using a for loop
mean.vc2 &lt;- 0
for (i in 1:n){
  mean.vc2 &lt;- mean.vc2 + vc[i]/n
}
mean.vc2</code></pre>
<pre><code>## [1] 16.96333</code></pre>
<pre class="r"><code># Compare to mean() function
mean(vc)</code></pre>
<pre><code>## [1] 16.96333</code></pre>
<pre class="r"><code># Standard deviation
var.vc &lt;- sum((vc - mean.vc)^2)/(n-1)
sd.vc &lt;- sqrt(var.vc)
sd.vc</code></pre>
<pre><code>## [1] 8.266029</code></pre>
<pre class="r"><code># Compare to sd() function
sd(vc)</code></pre>
<pre><code>## [1] 8.266029</code></pre>
<p>Below is a repeat of the above but for <code>OJ</code> (orange juice):</p>
<pre class="r"><code># Orange Juice
oj &lt;- dat[dat$supp==&#39;OJ&#39;, 1]

# Mean
n &lt;- length(oj)
mean.oj &lt;- sum(oj)/n
mean.oj</code></pre>
<pre><code>## [1] 20.66333</code></pre>
<pre class="r"><code># Can also compute using a for loop
mean.oj2 &lt;- 0
for (i in 1:n){
  mean.oj2 &lt;- mean.oj2 + oj[i]/n
}
mean.oj2</code></pre>
<pre><code>## [1] 20.66333</code></pre>
<pre class="r"><code># Compare to mean()
mean(oj)</code></pre>
<pre><code>## [1] 20.66333</code></pre>
<pre class="r"><code># Standard deviation
var.oj &lt;- sum((oj - mean.oj)^2)/(n-1)
sd.oj &lt;- sqrt(var.oj)
sd.oj</code></pre>
<pre><code>## [1] 6.605561</code></pre>
<pre class="r"><code># Compare to sd()
sd(oj)</code></pre>
<pre><code>## [1] 6.605561</code></pre>
<p>Trying to type the variance formula in plain-text is not visually appealing, nor helpful in communicating (it’s very difficult to read!). The beauty of LaTeX is the format is fairly intuitive, such as <code>$\frac{numerator}{denominator}$</code> will render as <span class="math inline">\(\frac{numerator}{denominator}\)</span> (the dollar signs indicate the start and end of the math setting, double-dollar sign will have the math rendered centre to the page). For example, the sample variance can be written as:</p>
<p><span class="math display">\[s^2 = \frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n-1}\]</span> Try to write the sample mean in LaTeX and quote the values computed in the R chunk above!</p>
<p>For the mean we can use <code>\bar{x}_n = \frac{\sum_{i=1}^n x_i}{n}</code>: <span class="math display">\[\bar{x}_n = \frac{\sum_{i=1}^n x_i}{n}\]</span></p>
</div>
<div id="simple-plots" class="section level2">
<h2>6. Simple Plots</h2>
<p>Numerical summaries can be powerful to provide concrete, numerical evidence to support our claims. Using graphical displays can also communicate clearly in a visual manner the story that our numbers tell, and can sometimes be a more powerful communication tool than numbers because we can <em>see</em> the <em>scale</em> of differences. Let’s use the <code>ggplot</code> package in <code>tidyverse</code> to produce side-by-side box plots of how tooth length growth differs between the two sources of vitamin C:</p>
<pre class="r"><code># Focus of this segment: understanding the layering language of ggplot
# Note also the R chunk options that control the alignment and size of
# The output figures

dat %&gt;% 
  ggplot(aes(x = supp, y = len)) +
  geom_boxplot() + # passing aes(x,y) into here works too!
  labs(title = &quot;Guinea Pig Tooth Length Growth by Vitamin C Source&quot;,
       subtitle = &quot;ToothGrowth Dataset&quot;,
       x = &quot;Vitamin C Source&quot;,
       y = &quot;Tooth Length Growth&quot;) +
  scale_x_discrete(labels = c(&quot;Orange Juice&quot;, &quot;Ascorbic Acid&quot;)) +
  theme_bw() # there are many different themes from which to choose!</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>What can we notice about tooth length growth between the two supplement groups?</p>
<p>Practice using visual and numeric features to:</p>
<ol style="list-style-type: decimal">
<li>Write a conclusion about any perceivable differences between the two sources of vitamin C.</li>
<li>Provide graphical and numerical features and their <span style="text-decoration:underline">interpretations</span>, explaining how they support your claim(s)!</li>
</ol>
<p>Here are things that we notice:</p>
<ul>
<li>The median tooth length growth for the orange juice supplement is almost at same level as the third quartile of tooth length growth for ascorbic acid.<br />
</li>
<li>There is some evidence which suggests that median tooth length growth for the orange juice supplement is statistically significantly larger than for the ascorbic acid supplement.</li>
<li>We can use a t-test to test for the difference in means between two groups. This is just a quick example but make sure to check the assumptions before proceeding!</li>
</ul>
<pre class="r"><code># Two-sided t-test
t.test(oj,vc)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  oj and vc
## t = 1.9153, df = 55.309, p-value = 0.06063
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.1710156  7.5710156
## sample estimates:
## mean of x mean of y 
##  20.66333  16.96333</code></pre>
<pre class="r"><code># One-sided t-test
t.test(oj,vc,&quot;greater&quot;)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  oj and vc
## t = 1.9153, df = 55.309, p-value = 0.03032
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  0.4682687       Inf
## sample estimates:
## mean of x mean of y 
##  20.66333  16.96333</code></pre>
<ul>
<li>From the two-sided t-test (p-value = 0.06), there is some evidence to suggest that the difference in tooth length growth between the two supplement groups is statistically significant.</li>
<li>From the one-sided t-test (p-value = 0.03), there is evidence to suggest that the mean tooth length growth for guinea pigs with orange juice supplements is statistically significantly greater than the mean tooth length growth for guinea pigs with ascorbic acid supplements.</li>
<li>Note that the p-value for the one-sided t-test is half the p-value for the two-sided t-test.</li>
</ul>
</div>
</div>
<div id="lab-1" class="section level1">
<h1>Lab 1</h1>
<p>In this R Lab, you will be guided by the TA to demonstrate the steps involved in performing an exploratory data analysis.</p>
<div id="r-lab-learning-goals-1" class="section level2">
<h2>R Lab Learning Goals</h2>
<ul>
<li>Load data from a local csv file</li>
<li>Formulate a question for EDA</li>
<li>Examine and pre-process your data using functions from the <code>tidyverse</code> package</li>
<li>Use the <code>lubridate</code> package for manipulating dates</li>
<li>Produce numerical summaries using the <code>summarize</code> function</li>
<li>Produce plots in ggplot to explore your EDA question</li>
</ul>
<pre class="r"><code># Load Required Packages
library(tidyverse)
library(lubridate)

# Set work directory
setwd(&quot;~/GitHub/dang-kevin.github.io/STA238&quot;)

# Read in Data
weather &lt;- read.csv(&quot;weatherstats_vancouver_daily.csv&quot;)

# Using file.choose() allows you to manually select the file you want
# weather &lt;- read.csv(file.choose())

# Quick overview of the data
glimpse(weather)</code></pre>
<pre><code>## Rows: 1,000
## Columns: 71
## $ X                             &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1~
## $ date                          &lt;chr&gt; &quot;2022-01-16&quot;, &quot;2022-01-15&quot;, &quot;2022-01-14&quot;~
## $ max_temperature               &lt;dbl&gt; 6.3, 7.0, 9.8, 11.1, 11.5, 10.0, 8.5, 6.~
## $ avg_hourly_temperature        &lt;dbl&gt; 5.29, 5.66, 6.94, 7.56, 9.87, 8.97, 4.78~
## $ avg_temperature               &lt;dbl&gt; 5.55, 5.15, 7.45, 7.50, 10.19, 8.35, 3.5~
## $ min_temperature               &lt;dbl&gt; 4.8, 3.3, 5.1, 3.9, 8.9, 6.7, -1.4, -1.5~
## $ max_humidex                   &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ min_windchill                 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, -2, -5, NA, ~
## $ max_relative_humidity         &lt;int&gt; 100, 100, 99, 99, 99, 99, 99, 99, 96, 99~
## $ avg_hourly_relative_humidity  &lt;dbl&gt; 99.0, 99.2, 95.7, 94.8, 96.8, 96.3, 93.4~
## $ avg_relative_humidity         &lt;dbl&gt; NA, 99.0, 93.0, 93.0, 94.5, 95.5, 91.5, ~
## $ min_relative_humidity         &lt;int&gt; 97, 98, 87, 87, 90, 92, 84, 84, 62, 58, ~
## $ max_dew_point                 &lt;dbl&gt; 6.1, 6.5, 7.4, 8.5, 10.2, 9.4, 6.9, 3.6,~
## $ avg_hourly_dew_point          &lt;dbl&gt; 5.1, 5.6, 6.3, 6.7, 9.4, 8.4, 3.8, 1.6, ~
## $ avg_dew_point                 &lt;dbl&gt; 5.3, 4.8, 6.3, 6.2, 9.2, 8.1, 3.4, 1.6, ~
## $ min_dew_point                 &lt;dbl&gt; 4.6, 3.1, 5.3, 4.0, 8.2, 6.8, -0.1, -0.5~
## $ max_wind_speed                &lt;int&gt; 11, 13, 14, 16, 23, 28, 28, 15, 24, 61, ~
## $ avg_hourly_wind_speed         &lt;dbl&gt; 4.96, 6.21, 7.67, 8.58, 15.88, 20.58, 15~
## $ avg_wind_speed                &lt;dbl&gt; 6.0, 8.0, 8.0, 9.0, 14.5, 21.0, 15.0, 8.~
## $ min_wind_speed                &lt;int&gt; 1, 3, 2, 2, 6, 14, 2, 1, 5, 7, 4, 7, 2, ~
## $ max_wind_gust                 &lt;int&gt; NA, NA, NA, NA, 38, 41, 38, NA, 32, 83, ~
## $ wind_gust_dir_10s             &lt;int&gt; NA, NA, NA, NA, 9, 10, 7, NA, 7, 29, 10,~
## $ max_pressure_sea              &lt;dbl&gt; 102.76, 102.90, 103.29, 103.06, 101.97, ~
## $ avg_hourly_pressure_sea       &lt;dbl&gt; 102.34, 102.82, 103.10, 102.30, 101.77, ~
## $ avg_pressure_sea              &lt;dbl&gt; 102.35, 102.81, 103.06, 102.37, 101.81, ~
## $ min_pressure_sea              &lt;dbl&gt; 101.94, 102.71, 102.83, 101.68, 101.64, ~
## $ max_pressure_station          &lt;dbl&gt; 102.71, 102.85, 103.24, 103.01, 101.92, ~
## $ avg_hourly_pressure_station   &lt;dbl&gt; 102.29, 102.77, 103.05, 102.25, 101.72, ~
## $ avg_pressure_station          &lt;dbl&gt; 102.30, 102.76, 103.01, 102.32, 101.75, ~
## $ min_pressure_station          &lt;dbl&gt; 101.89, 102.66, 102.78, 101.63, 101.59, ~
## $ max_visibility                &lt;int&gt; 16100, 24100, 48300, 48300, 32200, 32200~
## $ avg_hourly_visibility         &lt;dbl&gt; 6950.0, 10870.8, 31570.8, 34525.0, 17116~
## $ avg_visibility                &lt;int&gt; 8350, 12150, 33800, 36200, 19300, 18500,~
## $ min_visibility                &lt;int&gt; 600, 200, 19300, 24100, 6400, 4800, 1290~
## $ max_health_index              &lt;dbl&gt; 2.0, 2.2, 1.8, 2.3, 2.4, 2.3, 2.8, 3.0, ~
## $ avg_hourly_health_index       &lt;dbl&gt; 1.3, 1.5, 1.3, 1.7, 1.7, 1.8, 2.1, 2.0, ~
## $ avg_health_index              &lt;dbl&gt; 1.5, 1.6, 1.4, 1.6, 1.8, 1.8, 2.2, 2.2, ~
## $ min_health_index              &lt;dbl&gt; 1.0, 1.0, 1.0, 1.0, 1.2, 1.3, 1.7, 1.5, ~
## $ heatdegdays                   &lt;dbl&gt; 12.4, 12.8, 10.6, 10.5, 7.8, 9.7, 14.4, ~
## $ cooldegdays                   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~
## $ growdegdays_5                 &lt;dbl&gt; 0.6, 0.2, 2.5, 2.5, 5.2, 3.4, 0.0, 0.0, ~
## $ growdegdays_7                 &lt;dbl&gt; 0.0, 0.0, 0.4, 0.5, 3.2, 1.4, 0.0, 0.0, ~
## $ growdegdays_10                &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, ~
## $ precipitation                 &lt;dbl&gt; 0.0, 0.2, 0.0, 0.2, 29.3, 17.7, 4.6, 0.0~
## $ rain                          &lt;dbl&gt; NA, 0.2, 0.0, 0.2, 29.3, 17.7, 4.6, 0.0,~
## $ snow                          &lt;dbl&gt; NA, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0~
## $ snow_on_ground                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 1~
## $ sunrise                       &lt;chr&gt; &quot;08:01:00&quot;, &quot;08:02:00&quot;, &quot;08:03:00&quot;, &quot;08:~
## $ sunset                        &lt;chr&gt; &quot;16:43:00&quot;, &quot;16:42:00&quot;, &quot;16:40:00&quot;, &quot;16:~
## $ daylight                      &lt;dbl&gt; 8.70, 8.67, 8.62, 8.58, 8.57, 8.52, 8.50~
## $ sunrise_f                     &lt;dbl&gt; 8.02, 8.03, 8.05, 8.07, 8.07, 8.08, 8.08~
## $ sunset_f                      &lt;dbl&gt; 16.72, 16.70, 16.67, 16.65, 16.63, 16.60~
## $ min_uv_forecast               &lt;int&gt; 1, NA, 1, 1, NA, NA, NA, 1, NA, 1, NA, N~
## $ max_uv_forecast               &lt;int&gt; 1, NA, 1, 1, NA, NA, NA, 1, NA, 1, NA, N~
## $ min_high_temperature_forecast &lt;int&gt; 7, 7, 9, 9, 10, 10, 8, 6, 2, 3, 3, 2, 3,~
## $ max_high_temperature_forecast &lt;int&gt; 7, 8, 9, 10, 10, 10, 8, 6, 3, 3, 3, 2, 4~
## $ min_low_temperature_forecast  &lt;int&gt; 4, 5, 6, 6, 9, 6, 7, 0, 2, -1, 4, -2, -2~
## $ max_low_temperature_forecast  &lt;int&gt; 4, 5, 6, 6, 9, 9, 8, 0, 4, -1, 4, 0, -2,~
## $ solar_radiation               &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ max_cloud_cover_4             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ avg_hourly_cloud_cover_4      &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ avg_cloud_cover_4             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ min_cloud_cover_4             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ max_cloud_cover_8             &lt;int&gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8~
## $ avg_hourly_cloud_cover_8      &lt;dbl&gt; 6.7, 6.3, 8.0, 6.2, 7.9, 8.0, 6.9, 2.6, ~
## $ avg_cloud_cover_8             &lt;dbl&gt; 5.0, 4.5, 8.0, 4.5, 7.5, 8.0, 4.0, 4.0, ~
## $ min_cloud_cover_8             &lt;int&gt; 2, 1, 8, 1, 7, 8, 0, 0, 6, 1, 5, 2, 3, 6~
## $ max_cloud_cover_10            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ avg_hourly_cloud_cover_10     &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ avg_cloud_cover_10            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ min_cloud_cover_10            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~</code></pre>
<p>Note that since this data is from a csv file, functions like <code>?weather</code> will not provide us with information about the data set. For the purposes of this lab, we assume that the variable names are sufficiently informative to intuit their contents. In practice, however, information about the data and its variables can be found in a documentation file that is usually available from the source of the data.</p>
</div>
<div id="formulating-questions-for-eda" class="section level2">
<h2>1. Formulating questions for EDA</h2>
<p>Our goal during exploratory data analysis (EDA) is to develop an understanding of our data. Real data is complicated, often containing missing data and irregular formatting.</p>
<p>In this lab, we will demonstrate this process with the question: <strong>“What is the monthly total rainfall in Vancouver over 2021?”</strong></p>
</div>
<div id="checking-the-rain-variable" class="section level2">
<h2>2. Checking the <code>rain</code> variable</h2>
<p>The variable <code>rain</code> contains the daily rainfall measured in millimeters. Our first task is to check for any missing data. We could do this using the base R commands from Lab 0, but the code gets messy for complicated manipulations. Instead, we will use the pipe operator <code>%&gt;%</code> from the <code>tidyverse</code> package along with some data processing functions. The pipe operator <code>%&gt;%</code> allows us to take the output from one function and “pipe it in” to the argument of the next function. You will find that data manipulations using the pipe operator are much more readable than the equivalents in base R!</p>
<pre class="r"><code># Examples of pipe operator

#1. Pulling the first 5 rows of data containing date, rain, and average dew point

# Tidyverse way
weather %&gt;% 
  select(date, rain, avg_dew_point) %&gt;%
  head(5)</code></pre>
<pre><code>##         date rain avg_dew_point
## 1 2022-01-16   NA           5.3
## 2 2022-01-15  0.2           4.8
## 3 2022-01-14  0.0           6.3
## 4 2022-01-13  0.2           6.2
## 5 2022-01-12 29.3           9.2</code></pre>
<pre class="r"><code># base R way
head(weather[c(&quot;date&quot;, &quot;rain&quot;,&quot;avg_dew_point&quot;)], 5)</code></pre>
<pre><code>##         date rain avg_dew_point
## 1 2022-01-16   NA           5.3
## 2 2022-01-15  0.2           4.8
## 3 2022-01-14  0.0           6.3
## 4 2022-01-13  0.2           6.2
## 5 2022-01-12 29.3           9.2</code></pre>
<pre class="r"><code># head(weather[, c(&quot;date&quot;, &quot;rain&quot;,&quot;avg_dew_point&quot;)], 5)

#2. Adding new columns of data to the existing weather data:

# Tidyverse way
weather &lt;- weather %&gt;% 
  mutate(new_variable_1 = 1.5 * avg_hourly_temperature,
         new_variable_2 = rain + 10)

# base R way
weather$new_variable_1 &lt;- 1.5 * weather$avg_hourly_temperature
weather$new_variable_2 &lt;- weather$rain + 10</code></pre>
<p>First we will check which dates have missing rainfall data:</p>
<pre class="r"><code># Base R way
weather$date[is.na(weather$rain)]</code></pre>
<pre><code>##  [1] &quot;2022-01-16&quot; &quot;2022-01-05&quot; &quot;2021-12-30&quot; &quot;2020-12-08&quot; &quot;2020-12-07&quot;
##  [6] &quot;2020-12-06&quot; &quot;2020-12-05&quot; &quot;2020-12-04&quot; &quot;2020-12-03&quot; &quot;2020-12-02&quot;
## [11] &quot;2020-12-01&quot;</code></pre>
<pre class="r"><code># Tidyverse way
weather %&gt;% 
  filter(is.na(rain)) %&gt;% 
  # can also use select(date)
  pull(date)</code></pre>
<pre><code>##  [1] &quot;2022-01-16&quot; &quot;2022-01-05&quot; &quot;2021-12-30&quot; &quot;2020-12-08&quot; &quot;2020-12-07&quot;
##  [6] &quot;2020-12-06&quot; &quot;2020-12-05&quot; &quot;2020-12-04&quot; &quot;2020-12-03&quot; &quot;2020-12-02&quot;
## [11] &quot;2020-12-01&quot;</code></pre>
<pre class="r"><code># To show the days that DO NOT have missing rain values, add &#39;!&#39; in front of is.na()
# e.g. weather$date[!is.na(weather$rain)]</code></pre>
<p>We see that there is one missing value of rainfall in the year 2021. This might be a cause for concern if this was a day with particularly high rainfall. Unfortunately, we do not know if this was the case. The best we can do in these situations is to tell the reader that what is missing from our data so that they are aware of the limitations of our analysis.</p>
</div>
<div id="formatting-the-date-variable" class="section level2">
<h2>3. Formatting the <code>date</code> variable</h2>
<p>Since we are concerned with total monthly rainfall, our next task is to convert the <code>date</code> variable into a form that is amenable to analysis. First we examine the format <code>date</code>:</p>
<pre class="r"><code># str() compactly displays the structure of an object
# Good alternative to glimpse()
str(weather$date)</code></pre>
<pre><code>##  chr [1:1000] &quot;2022-01-16&quot; &quot;2022-01-15&quot; &quot;2022-01-14&quot; &quot;2022-01-13&quot; ...</code></pre>
<p>We find that each entry of <code>date</code> is a character vector of the form “YYYY-MM-DD”. To prepare this data for use in <code>lubridate</code>, we convert <code>date</code> from a character vector to a datetime object.</p>
<pre class="r"><code># First we convert date to a datetime object
# To explain format, look at `?strptime`

# The base R way
weather$date &lt;- as.Date(weather$date, format = &quot;%Y-%m-%d&quot;)

# The tidyverse way using mutate()
# Make sure to reassign the dataset to ensure that the mutation step is saved
weather &lt;- weather %&gt;% 
  mutate(date = as.Date(date, format = &quot;%Y-%m-%d&quot;))</code></pre>
<p>Now that we have a datetime object, we can use functions from <code>lubridate</code> to easily convert <code>date</code> into many useful quantities. We use the functions <code>year</code>, <code>month</code>, and <code>day</code> to define the corresponding variables in our data</p>
<pre class="r"><code>######################################################################
###  NOTE: There is an &#39;eval=F&#39; in the R Chunk Option! Make sure to ##
###        delete this before knitting!!                            ##
######################################################################

# Demonstrate some lubridate functions

# Extract weekday as character
weekdays(weather$date) %&gt;% str()</code></pre>
<pre><code>##  chr [1:1000] &quot;Sunday&quot; &quot;Saturday&quot; &quot;Friday&quot; &quot;Thursday&quot; &quot;Wednesday&quot; &quot;Tuesday&quot; ...</code></pre>
<pre class="r"><code># Extract month as integer
lubridate::month(weather$date) %&gt;% str()</code></pre>
<pre><code>##  num [1:1000] 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<pre class="r"><code># Extract month as ordered factor
month(weather$date, label = TRUE) %&gt;% str()</code></pre>
<pre><code>##  Ord.factor w/ 12 levels &quot;Jan&quot;&lt;&quot;Feb&quot;&lt;&quot;Mar&quot;&lt;..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<pre class="r"><code># Extract the year as integer
year(weather$date) %&gt;% str()</code></pre>
<pre><code>##  num [1:1000] 2022 2022 2022 2022 2022 ...</code></pre>
<pre class="r"><code># summarizing the pieces above
# Create the year, month, and day variables
weather &lt;- weather %&gt;%
  mutate(year = year(date),
         month = month(date, label = TRUE),
         day = day(date))</code></pre>
</div>
<div id="filtering-and-summarizing-the-data" class="section level2">
<h2>4. Filtering and summarizing the data</h2>
<p>Now that we have examined and processed our data, we can start to answer our original question: “What is the monthly total rainfall in Vancouver over 2021?” To begin, we might use <code>filter</code> and <code>select</code> to inspect our data</p>
<pre class="r"><code>weather %&gt;% 
  filter(year == 2021) %&gt;% 
  select(year, month, day, rain) %&gt;% 
  head(10)</code></pre>
<pre><code>##    year month day rain
## 1  2021   Dec  31  0.0
## 2  2021   Dec  30   NA
## 3  2021   Dec  29  0.0
## 4  2021   Dec  28  0.0
## 5  2021   Dec  27  0.0
## 6  2021   Dec  26  0.0
## 7  2021   Dec  25  0.0
## 8  2021   Dec  24  5.1
## 9  2021   Dec  23  2.4
## 10 2021   Dec  22  3.4</code></pre>
<p>This output, however, is not as helpful as a numerical summary of the data. The function <code>group_by</code> and <code>summarize</code> provide a useful method for summarizing the data. First we choose a variable(s) to group by and then we define the numerical summaries we wish to compute. For example, we might be interested in the mean and the maximum rainfall each month.</p>
<pre class="r"><code># Assign to new dataframe to use for plotting
df &lt;- weather %&gt;% 
  filter(year == 2021) %&gt;% 
  group_by(month) %&gt;% 
  summarise(rain_tot = sum(rain, na.rm = T),
            rain_max = max(rain, na.rm = T))

df</code></pre>
<pre><code>## # A tibble: 12 x 3
##    month rain_tot rain_max
##    &lt;ord&gt;    &lt;dbl&gt;    &lt;dbl&gt;
##  1 Jan      176.      29.5
##  2 Feb       75       19.2
##  3 Mar       34        6  
##  4 Apr       38       13.5
##  5 May       30.2      8.2
##  6 Jun       37.2     12.5
##  7 Jul        0        0  
##  8 Aug       36.7     22.1
##  9 Sep      155       50.9
## 10 Oct      148.      43.3
## 11 Nov      312.      52.5
## 12 Dec       93.5     31.3</code></pre>
<p>These numerical summaries may be useful in some contexts, but a graph is generally better for examining these summaries. Thankfully, the results of the summary can easily be piped into ggplot to make such graphs!</p>
<pre class="r"><code>df %&gt;% 
  ggplot(aes(x = month, y = rain_tot)) +
  geom_col(fill = &quot;skyblue&quot;) +
  labs(title = &quot;Total monthly rainfall, Vancouver 2021&quot;,
       x = &quot;Month&quot;,
       y = &quot;Total rainfall (mm)&quot;) +
  # Alternative labelling method instead of labs()
  # ggtitle(&quot;Total monthly rainfall, Vancouver 2021&quot;) +
  # xlab(&quot;Month&quot;) +
  # ylab(&quot;Total rainfall (mm)&quot;) +
  theme_bw()</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-18-1.png" width="768" /></p>
<p>Some quick observations:</p>
<ul>
<li>No rainfall in July.</li>
<li>A lot of rain in November!</li>
</ul>
</div>
</div>
<div id="lab-2" class="section level1">
<h1>Lab 2</h1>
<p>In this R Lab, you will be guided by the TA to demonstrate the steps involved in estimator analysis.</p>
<div id="r-lab-learning-goals-2" class="section level2">
<h2>R Lab Learning Goals</h2>
<ul>
<li>Review and implement the inverse CDF method</li>
<li>Compute a point estimate for an estimator on a sample</li>
<li>Perform a simulation study to investigate the sampling distribution of an estimator</li>
<li>Learn about R’s <code>apply</code> functions for looping</li>
<li>Use the package <code>gridExtra</code> and the function <code>grid.arrange</code> to combine plots, and <code>latex2exp</code> to include relevant details in plot labels</li>
</ul>
</div>
<div id="motivation" class="section level2">
<h2>0. Motivation</h2>
<p>In our work we often find ourselves simulating data from a probability distributions. R provides built-in functions to simulate from the most common distributions (e.g. <code>rnorm</code>, <code>rbinom</code>, etc. ), but we sometimes need to sample from a distribution that is not included in base R.</p>
<p>Fortunately, the inverse CDF method provides an all-purpose method for simulating from continuous probability densities, and in the next section we will demonstrate how it can be used to sample from an arbitrary continuous density provided we know the CDF and its inverse.</p>
</div>
<div id="the-inverse-cdf-method" class="section level2">
<h2>1. The inverse CDF method</h2>
<p>Suppose <span class="math inline">\(X\)</span> is a continuous random variable with distribution function <span class="math inline">\(F\)</span>. A realization of <span class="math inline">\(X\)</span> can be simulated as follows:</p>
<ol style="list-style-type: decimal">
<li>Simulate a uniform random variable <span class="math inline">\(U\sim \text{Uniform(0,1)}\)</span></li>
<li>Assign <span class="math inline">\(X = F^{-1}(U)\)</span></li>
</ol>
<p>To demonstrate this method, consider the following unusual density function, <span class="math display">\[\begin{equation*}
f(x; \alpha) = 
\begin{cases}
\frac{\alpha}{\alpha - 1} \frac{1}{x^2}, &amp; 1 &lt; x \leq \alpha,\\
0 &amp; \text{otherwise} 
\end{cases}
\end{equation*}\]</span> This density is definitely not included in R, so its a perfect opportunity to use the inverse CDF method!</p>
<div id="mathematical-expressions" class="section level3">
<h3>Mathematical expressions</h3>
<p>The first step will be to find the distribution function <span class="math inline">\(F\)</span>. By integration we find that <span class="math display">\[\begin{equation*}
F(x) = 
\begin{cases}
0 &amp; x \leq 1 \\
\frac{\alpha}{\alpha - 1}\left(1 - \frac{1}{x}\right) &amp; 1 &lt; x \leq \alpha \\
1 &amp; \alpha &lt; x.
\end{cases}
\end{equation*}\]</span> Next we find the inverse CDF by setting <span class="math inline">\(u = F(x)\)</span>, <span class="math inline">\((u \in [0,1])\)</span>, and solving for <span class="math inline">\(x\)</span>: <span class="math display">\[\begin{equation*}
F^{-1}(u) =  \left[1 - \frac{\alpha - 1}{\alpha}u\right]^{-1}, \quad (u \in [0,1]).
\end{equation*}\]</span></p>
</div>
<div id="implementing-method" class="section level3">
<h3>Implementing Method</h3>
<p>With these expressions we can now program a function <code>rdens</code> to sample from the linear density <span class="math inline">\(f\)</span> using the inverse CDF method.</p>
<pre class="r"><code># Define the inverse CDF
F_inv &lt;- function(u, a){
  (1-((a-1)/a)*u)^(-1)
}

# Define a function that performs the sampling
rdens &lt;- function(n,a){
  u &lt;- runif(n) # u &lt;- runif(n = n, min = 0, max = 1)
  x &lt;- F_inv(u, a)
  return(x)
}</code></pre>
<p>It is important to verify that our function <code>rdens</code> behaves as expected. To check our function, we’ll plot a few samples of size <span class="math inline">\(n = 5000\)</span> from the function to make sure the density looks correct.</p>
<pre class="r"><code>library(tidyverse)
library(latex2exp)

# Plot the result
data.frame(x = rdens(n = 5000, a = 10)) %&gt;%
  ggplot(aes(x = x, y = ..density..)) +
  geom_histogram(binwidth = 0.2, center = 0.1) + 
  ggtitle(label = TeX(r&#39;(A sample from $f(x)$)&#39;), 
          subtitle = TeX(r&#39;($n = 5000, \alpha = 10$)&#39;)) +
  theme_bw()</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="constructing-an-estimator" class="section level2">
<h2>2. Constructing an Estimator</h2>
<p>Now that we can sample from our distribution, we might be interested in the behaviour of certain estimators. Suppose we wish to estimate the parameter <span class="math inline">\(\alpha\)</span> using a sample from the distribution. Since <span class="math inline">\(\alpha\)</span> controls the width of the distribution, we might try estimating it using the maximum value of our sample. By the expression for the density, we define our estimator to be <span class="math display">\[
\hat \alpha = \max(X_1,...,X_n)
\]</span> It is easy to compute this estimate for each sample we generate using <code>rdens</code>. All that is needed is to evaluate <code>max</code> on each sample. For generalizability, we will write a wrapper function <code>get_ahat</code>.</p>
<pre class="r"><code># Write wrapper function
get_ahat &lt;- function(x){max(x)}

# Evaluate the estimator on a sample
ahat &lt;- get_ahat(rdens(n = 100, a = 10))
cat(ahat)</code></pre>
<pre><code>## 9.742614</code></pre>
<p>By re-running the above chunk we see that there is substantial variation in the results and the estimates never quite reach the true value of <span class="math inline">\(10\)</span>. Thus it appears that our estimator is biased downwards, however it is not easy to calculate this bias due to the form of the estimator. In these cases, we typically turn to simulation methods to examine the estimator.</p>
</div>
<div id="bias-of-the-estimator" class="section level2">
<h2>3. Bias of the Estimator</h2>
<p>In this section, we will construct a simulation study to estimate the bias of the estimator when the sample size is <span class="math inline">\(n = 100\)</span> and the true value of the parameter is <span class="math inline">\(\alpha = 10\)</span>. To do this, we will simulate 1000 independent samples of size 100 from the density and compute the estimate on each of the samples. From this we will obtain a sample from the sampling distribution of the estimator, which we can then use to estimate the bias and other quantities.</p>
<pre class="r"><code># Simulate 1000 datasets of size 100
sim &lt;- replicate(n = 1000, rdens(n = 100, a = 10))
str(sim)</code></pre>
<pre><code>##  num [1:100, 1:1000] 1.23 1.64 1.23 1.21 1.85 ...</code></pre>
<pre class="r"><code># For each sample (each column), compute the statistic
ahat &lt;- apply(sim, MARGIN = 2, FUN = get_ahat)
str(ahat)</code></pre>
<pre><code>##  num [1:1000] 9.38 9.24 8.63 9.28 9.51 ...</code></pre>
<p>Now that we have a sample of size <span class="math inline">\(1000\)</span> from the sampling distribution of <span class="math inline">\(\hat\alpha\)</span>, we plot it to learn more about the distribution</p>
<pre class="r"><code># Plot the sampling distribution of the estimator
data.frame(ahat) %&gt;%
  ggplot(aes(x = ahat, y = ..density..)) +
  geom_histogram(binwidth = 0.2, center = 0.1) +
  ggtitle(
    label = TeX(r&#39;(Sampling distribution for $\hat{\alpha}$)&#39;),
    subtitle = TeX(r&#39;($n = 100, \alpha = 10$, (1000 replications))&#39;)) +
  xlab(TeX(r&#39;($\hat{\alpha}$)&#39;)) +
  theme_bw()</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>From the above sampling distribution, we get a better idea of its sampling variation, bias, as well as any skewness of the distribution which is difficult to determine from numeric summaries alone. To get a more precise estimate of the bias, we simply compute the mean of the sampling distribution and subtract it from the true value <span class="math inline">\(\alpha = 10\)</span>.</p>
<pre class="r"><code># Estimated bias of the estimator
bias &lt;- mean(ahat) - 10
cat(bias)</code></pre>
<pre><code>## -0.8000599</code></pre>
<pre class="r"><code># 95% credible interval
ci &lt;- quantile(ahat, probs = c(0.025, 0.975))
cat(ci)</code></pre>
<pre><code>## 7.329384 9.967306</code></pre>
</div>
<div id="consistency-of-the-estimator" class="section level2">
<h2>4. Consistency of the Estimator</h2>
<p>A natural question once we have an estimator is whether or not it is consistent, that is, as the sample size increases does the estimator converge in probability to the true value. Once again, this is typically difficult to prove analytically, so we might satisfy ourselves by examining the behaviour of the estimator via a simulation study. To do this, we simulate the sampling distribution of the estimator for sample sizes of <span class="math inline">\(n = 50\)</span>, <span class="math inline">\(100\)</span>, <span class="math inline">\(500\)</span>, and <span class="math inline">\(1000\)</span> and plot the distributions.</p>
<pre class="r"><code># Function for simulations
sim_study &lt;- function(B, n, a){
  # Simulate B samples of size n
  sim &lt;- replicate(n = B, rdens(n = n, a = a))
  ahat &lt;- apply(sim, MARGIN = 2, FUN = get_ahat)
  
  # Compute bias
  bias &lt;- mean(ahat) - a
  
  # Plot
  fig &lt;- data.frame(ahat) %&gt;%
  ggplot(aes(x = ahat, y = ..density..)) +
  geom_histogram(binwidth = 0.2, center = 0.1) +
  scale_x_continuous(limits = c(5,10)) +
  ggtitle(paste0(&quot;n =&quot;, n)) +
  xlab(TeX(r&#39;($\hat{\alpha}$)&#39;)) +
  theme_bw()
  
  return(list(fig = fig, bias = bias))
}

# Set parameters of simulation study
a &lt;- 10
B &lt;- 1000
n &lt;- c(50, 100, 500, 1000)

# Set seed for reproducibility
set.seed(324)

# Run simulation for each value in n
result &lt;- lapply(n, function(n) sim_study(B = B, n = n, a = a))
names(result) &lt;- paste0(&quot;n_&quot;, n)</code></pre>
<pre class="r"><code># Plot all four plots on a grid using grid.arrange
library(gridExtra)
grid.arrange(result$n_50$fig,
             result$n_100$fig,
             result$n_500$fig,
             result$n_1000$fig)</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-27-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>From the above plots, what can you say about the estimator as the sample size increases? Does it appear consistent? Is the bias shrinking? How else does the distribution change?</p>
<p>We can also see our numeric estimates of the bias as follows:</p>
<pre class="r"><code># Print the bias in a data.frame
bias &lt;- lapply(result, function(x) x$bias) %&gt;% as.data.frame()
bias</code></pre>
<pre><code>##        n_50      n_100      n_500      n_1000
## 1 -1.311561 -0.7815966 -0.1703174 -0.09099329</code></pre>
</div>
</div>
<div id="lab-3" class="section level1">
<h1>Lab 3</h1>
<p>In this R Lab, you will be guided by your TA through a second example of constructing empirical bootstrapped confidence intervals (like we did in class this week). You will also learn how to produce your own Normal QQ plots as a means of verifying normality of data.</p>
<div id="r-lab-learning-goals-3" class="section level2">
<h2>R Lab Learning Goals</h2>
<ul>
<li>Review how to read in data and check for missing values</li>
<li>Review steps to construct a confidence interval via empirical bootstrapping</li>
<li>Learn how to produce a normal QQ plot to check for evidence of non-normality (violations in normality)</li>
<li>Implement empirical bootstrap and construct your own <span class="math inline">\(95\%\)</span> bootstrap confidence interval</li>
<li>Interpret the interval constructed</li>
</ul>
</div>
<div id="motivation-1" class="section level2">
<h2>0. Motivation</h2>
<p>In this lab we will be considering laboratory values associated with diagnosing Type 2 diabetes, specifically glycated hemoglobin (A1C). Diabetes mellitus is one of the leading causes of death in the United States and estimating population-level prevalence is therefore an area of interest in public health research. This data is a subset of <a href="https://www.cdc.gov/nchs/nhanes/index.htm">The Nation’s Mobile Health Survey (NHANES)</a> survey for 2017-2018.</p>
</div>
<div id="formulate-a-research-question" class="section level2">
<h2>1. Formulate a research question</h2>
<p>In this presentation we will be considering the following research question:</p>
<p><em>“What is the average value of A1C in the U.S. population in the period 2017-2018?”</em></p>
<p>Investigating this question provides us with a crude index for the prevalence of diabetes in the U.S. population.</p>
<p>Since our inferences are based on a small sample from the whole population, we will want to quantify the uncertainty in our estimates due to sampling variation. To this end, we will construct confidence intervals for our estimates using a bootstrap approach.</p>
</div>
<div id="data-preparation" class="section level2">
<h2>2. Data preparation</h2>
<p>The first task is to load the NHANES data into memory using the function <code>read.csv</code>.</p>
<pre class="r"><code>library(tidyverse)
library(latex2exp)

# Load the Data:
# It may be helpful to manually set your working directory using `setwd`
setwd(&quot;~/GitHub/dang-kevin.github.io/STA238&quot;)
diabetes &lt;- read.csv(&quot;diabetes.csv&quot;)

# Get a summary of the variables in the nhanes data
# str(diabetes)
glimpse(diabetes)</code></pre>
<pre><code>## Rows: 135
## Columns: 3
## $ seqn &lt;int&gt; 100934, 99455, 99224, 99184, 97031, 98571, 96236, 101113, 95690, ~
## $ gh   &lt;dbl&gt; 4.8, 5.2, 5.4, 5.6, 5.2, 5.0, 8.3, 5.8, 7.4, 4.9, 4.9, 5.4, 5.4, ~
## $ fpg  &lt;int&gt; 79, 108, 103, 103, 98, 88, 107, 98, 106, 106, 90, 103, 101, 104, ~</code></pre>
<p>In the above printout, <code>seqn</code> is a subject ID number in the database, <code>gh</code> is the percentage of glycated hemoglobin (A1C), and <code>fpg</code> is fasting plasma glucose in mm/dL. The latter two variables are lab measurements used for diagnosing Type II diabetes, though our focus in the presentation portion of the lab will be on the A1C values in <code>gh</code>.</p>
<p>Before we get started on the analysis proper, it is a good idea to account for any missing values in the data.</p>
<pre class="r"><code># Print a summary of `gh` to check for missing data
summary(diabetes)</code></pre>
<pre><code>##       seqn              gh              fpg       
##  Min.   : 93732   Min.   : 4.600   Min.   : 74.0  
##  1st Qu.: 96355   1st Qu.: 5.275   1st Qu.: 95.0  
##  Median : 99289   Median : 5.500   Median :103.0  
##  Mean   : 98779   Mean   : 5.791   Mean   :111.9  
##  3rd Qu.:101137   3rd Qu.: 5.800   3rd Qu.:112.0  
##  Max.   :102935   Max.   :10.900   Max.   :313.0  
##                   NA&#39;s   :11       NA&#39;s   :11</code></pre>
<p>We see from the summary printout that there are 11 missing values. For the purposes of this lab we simply note this fact and remove them from the data.</p>
<pre class="r"><code># For this analysis, we remove missing values 
# You learned other methods of doing this in R Lab #1

diabetes &lt;- diabetes[complete.cases(diabetes),]

# diabetes &lt;- na.omit(diabetes)</code></pre>
</div>
<div id="a-point-estimate" class="section level2">
<h2>3. A point estimate</h2>
<p>Recall that our goal is to estimate the mean A1C of the U.S. population from 2017-2018.</p>
<p>The estimate based on our sample is:</p>
<pre class="r"><code># Compute the mean A1C in our sample
x_bar &lt;- mean(diabetes$gh)
x_bar</code></pre>
<pre><code>## [1] 5.791129</code></pre>
<p>We would, however, like to include a confidence interval for this estimate to reflect the uncertainty in our estimate due to sampling variability. In the next sections we will demonstrate how we will use a bootstrap approach to construct this confidence interval.</p>
</div>
<div id="bootstrap-confidence-intervals" class="section level2">
<h2>4. Bootstrap confidence intervals</h2>
<p>The first component of any bootstrap approach is deciding how the bootstrapped datasets will be simulated; will we use a parametric or empirical approach? To help us decide, we should first examine the distribution of our data to see if it resembles a parametric density or not.</p>
<pre class="r"><code>###########################################
### Remove the eval=F from the R chunk! ###
###########################################

# Histogram of `gh`
diabetes %&gt;% 
  ggplot(aes(x = gh)) +
  geom_histogram(aes(y=..density..), 
                 binwidth = 0.2,
                 fill = &#39;thistle2&#39;,
                 colour = &#39;black&#39;) +
  labs(title = &quot;Sample distribution of A1C&quot;,
       x = &quot;A1C&quot;,
       y = &quot;Density&quot;)</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-33-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>On inspection, this distribution looks like it is positively-skewed, and that a parametric bootstrap based on a normal sampling distribution is inappropriate. To get a closer look, we can plot the quantiles of the sample against a normal distribution in a Q-Q plot.</p>
<pre class="r"><code>###########################################
### Remove the eval=F from the R chunk! ###
###########################################

# QQ-plot to assess normality of `gh`
diabetes %&gt;% 
  ggplot(aes(sample = gh)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = &quot;Normal Q-Q plot&quot;,
       subtitle = &quot;Data: A1C&quot;,
       x = TeX(r&#39;($N(0,1)$ Quantiles)&#39;),
       y = &quot;A1C Quantiles&quot;)</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-34-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The Q-Q plot confirms our suspicions that the data in non-normally distributed. Indeed, about 16% of A1C values reside in the heavy tails of the sample. (To see this, note that the points that leave the normal line fall above the <span class="math inline">\(N(0,1)\)</span> quantile value of <span class="math inline">\(Z \approx 1\)</span>, which corresponds to <span class="math inline">\(P(Z \geq 1) \approx 0.16\)</span>.)</p>
<p>Because of this non-normality, we opt for an empirical bootstrap approach to construct confidence intervals for the mean A1C.</p>
</div>
<div id="simulation" class="section level2">
<h2>5. Simulation</h2>
<p>To construct the confidence intervals, we will used what is called <em>studentized bootstrap confidence intervals</em>. This involves computing the studentized mean <span class="math display">\[
t^* = \frac{\bar x_n^* - \bar x_n}{s^*_n/\sqrt n}
\]</span> for each bootstrap sample, where <span class="math inline">\(\bar x_n^*\)</span> and <span class="math inline">\(s^*_n\)</span> are the bootstrap mean and standard deviation, respectively, and <span class="math inline">\(\bar x_n\)</span> is the sample mean of the original data. The confidence interval for the population mean <span class="math inline">\(\mu\)</span> is then <span class="math display">\[
\left(\bar x_n - c_u^*\frac{s_n}{\sqrt{n}}, \bar x_n - c_l^*\frac{s_n}{\sqrt{n}}\right),
\]</span> where <span class="math inline">\(c_l^*\)</span> and <span class="math inline">\(c_u^*\)</span> are the lower and upper critical values of the sampling distribution of <span class="math inline">\(t^*\)</span> that give the desired significance level. In this lab, we will construct a <span class="math inline">\(95\%\)</span> confidence interval by taking <span class="math inline">\(c_l^*\)</span> and <span class="math inline">\(c_u^*\)</span> to be the <span class="math inline">\(2.5\%\)</span> and <span class="math inline">\(97.5\%\)</span> quantiles of the sampling distribution, respectively.</p>
<pre class="r"><code>## Using For-Loop

# Define the required inputs:
mean.sample &lt;- mean(diabetes$gh) # sample mean of original data
sd.sample &lt;- sd(diabetes$gh) #sample sd of original data
B &lt;-  2000
n.sample &lt;- length(diabetes$gh)
sim.t &lt;- c() #empty vector to store studentized means

## Bootstrapping Step ##
for (i in 1:B){
  boot.sample &lt;- sample(diabetes$gh, n.sample, replace = T)
  boot.mean &lt;- mean(boot.sample)
  boot.sd &lt;- sd(boot.sample)
  
  # Compute studentized mean and store it into sim.t
  sim.t[i] &lt;- (boot.mean-x_bar)/(boot.sd/sqrt(n.sample))
}

## Find the Critical Values ##
(crit.t &lt;- quantile(sim.t, probs = c(0.975, 0.025)))</code></pre>
<pre><code>##     97.5%      2.5% 
##  1.676319 -2.351053</code></pre>
<pre class="r"><code># Compute Bootstrapped CI 
(ci.student &lt;- mean.sample - crit.t*sd.sample/sqrt(n.sample))</code></pre>
<pre><code>##    97.5%     2.5% 
## 5.639214 6.004191</code></pre>
<p>Since we know that if we performed this analysis many times on new samples of people, the true population mean A1C would be contained in any interval calculated in the above method in <span class="math inline">\(95\%\)</span> of replications, this allows us to interpret the calculated interval: We can say that based on our data, we are 95% confident that the average A1C in the population could be as low as 5.6392143 to as high as 6.0041909. (The interpretation of confidence intervals can be tricky!)</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
