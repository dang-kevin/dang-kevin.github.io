<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>STA238: Probability, Statistics and Data Analysis II</title>

<script src="site_libs/header-attrs-2.21/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.2.1/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.2.1/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Kevin Dang</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-university"></span>
     
    Teaching
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="CHL5202.html">
        <span class="fa fa-book"></span>
         
        CHL5202 - Winter 2022
      </a>
    </li>
    <li>
      <a href="STA238.html">
        <span class="fa fa-book"></span>
         
        STA238 - Winter 2022
      </a>
    </li>
    <li>
      <a href="STA237.html">
        <span class="fa fa-book"></span>
         
        STA237 - Fall 2021
      </a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-project-diagram"></span>
     
    Projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="cognitive.html">
        <span class="fa fa-code"></span>
         
        Cognitive Flexibility
      </a>
    </li>
    <li>
      <a href="EDA.html">
        <span class="fa fa-code"></span>
         
        Exploratory Data Analysis
      </a>
    </li>
    <li>
      <a href="heart.html">
        <span class="fa fa-code"></span>
         
        Heart Disease Classifier
      </a>
    </li>
    <li>
      <a href="mice.html">
        <span class="fa fa-code"></span>
         
        Mice Protein Expression
      </a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="work.html">
    <span class="fa fa-user"></span>
     
    Work History
  </a>
</li>
<li>
  <a href="files/Resume_Kevin_Dang.pdf">
    <span class="fa fa-file-pdf-o"></span>
     
    Resume
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">STA238: Probability, Statistics and Data
Analysis II</h1>

</div>


<div id="course-description" class="section level1 unlisted unnumbered">
<h1 class="unlisted unnumbered">Course Description</h1>
<p>An introduction to statistical inference and practice. Statistical
models and parameters, estimators of parameters and their statistical
properties, methods of estimation, confidence intervals, hypothesis
testing, likelihood function, the linear model. Use of statistical
computation for data analysis and simulation.</p>
<p>Course material provided by Professor Karen Huynh Wong and
modifications were made by myself.</p>
</div>
<div id="lab-0" class="section level1">
<h1>Lab 0</h1>
<p>In this R Lab, you will be guided by your TA to familiarize yourself
with the R environment, using and formatting in R Markdown, and
producing well-organized outputs.</p>
<div id="r-lab-learning-goals" class="section level2">
<h2>R Lab Learning Goals</h2>
<ul>
<li>Install and load packages in R, use them in an R Markdown file</li>
<li>Simple computations and referring to <code>?command_name</code> to
find the documentation of various commands</li>
<li>Select elements, columns, or rows from a dataset</li>
<li>Produce simple plots in ggplot with informative and clearly
formatted titles + labels</li>
<li>Use LaTeX notation to neatly and correctly display math notation.
You can knit this document as you type (which also helps you identify
bugs in your code!) to see how the format of the text translates into
the finished product, such as creating headers, bold-facing, and math
notation!</li>
<li>Knit your document to a finished document that includes written text
and properly rendered math notation, with plots and source code
separately embedded</li>
</ul>
<p>Some additional resources you may find helpful as you learn is the <a
href="https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf">R
Markdown Cheatsheet</a> and the <a
href="http://tug.ctan.org/info/undergradmath/undergradmath.pdf">LaTeX
Cheatsheet</a>. As you work more in LaTeX, the notation will get easier
and become second nature!</p>
</div>
<div id="install-and-load-packages" class="section level2">
<h2>1. Install and Load Packages</h2>
<p>R packages are a collection of functions, code, and data sets that
are developed by others and can be used to supplement the basic tools in
R. R comes with some basic packages, but working with them can be
sometimes clunky. You’ll begin by learning how to install packages and
load packages, and the difference between these two actions!</p>
<p>Begin by installing and loading the <code>tidyverse</code> package,
which is a collection of R packages. We will use this extensively in our
course, as all packages within share similar structure and design,
making it a very intuitive and versatile tool to master!</p>
<p><strong>Note: Never include a package install in your R chunks in an
R Markdown file. R will not be able to knit your document! Instead, run
it strictly within your console.</strong></p>
<pre class="r"><code># Students: What do you think the &#39;message = F&#39; in the R chunk option does? 
# Try knitting your document with and without the option

# Can also try `warning = F` to hide warnings
# echo = F` to run the chunk but hide the code

# install.packages(&quot;tidyverse&quot;)
library(tidyverse)

# Use Ctrl + Alt + I shortcut for creating code chunks</code></pre>
</div>
<div id="loading-data-and-saving-it-to-an-object"
class="section level2">
<h2>2. Loading Data and Saving it to an Object</h2>
<p>Let’s examine some datasets that are already available in R (see
<code>library(help = "datasets")</code> for a list of datasets in base
R), starting with the ToothGrowth dataset.</p>
<pre class="r"><code># ?ToothGrowth

# Variable Assignment
dat &lt;- ToothGrowth

# Mostly useful for smaller datasets, but for larger ones we prefer to use glimpse and summary
# View(dat)

glimpse(dat)</code></pre>
<pre><code>## Rows: 60
## Columns: 3
## $ len  &lt;dbl&gt; 4.2, 11.5, 7.3, 5.8, 6.4, 10.0, 11.2, 11.2, 5.2, 7.0, 16.5, 16.5, 15.2, 17.3, 22.5, 17.3, 13.6, 14.5, 18.8, 15.5, 23.6, 18.5, 33.9, 25.5, 26.4, 32.5, 26.7, 21.5…
## $ supp &lt;fct&gt; VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, OJ, OJ, OJ, OJ, OJ, OJ, OJ, OJ, OJ, OJ, …
## $ dose &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.5, 0.5, …</code></pre>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##       len        supp         dose      
##  Min.   : 4.20   OJ:30   Min.   :0.500  
##  1st Qu.:13.07   VC:30   1st Qu.:0.500  
##  Median :19.25           Median :1.000  
##  Mean   :18.81           Mean   :1.167  
##  3rd Qu.:25.27           3rd Qu.:2.000  
##  Max.   :33.90           Max.   :2.000</code></pre>
</div>
<div id="simple-data-filtration" class="section level2">
<h2>3. Simple Data Filtration</h2>
<p>It looks like there are two groups of data in the
<code>ToothGrowth</code> data set. What are they?</p>
<p>What if you only want to study the growth based on one source of
vitamin C? How do you go about extracting this information?</p>
<pre class="r"><code># After loading and examining your data, and learning about selecting columns or elements
# from your data set, consider the following two commands below. 
# Briefly comment below what these two commands do:

# What does
which(dat$supp == &#39;VC&#39;) #do?</code></pre>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30</code></pre>
<pre class="r"><code># Extracts which indices are TRUE</code></pre>
<pre class="r"><code># What does 
dat[dat$supp==&#39;VC&#39;, 1] #do?</code></pre>
<pre><code>##  [1]  4.2 11.5  7.3  5.8  6.4 10.0 11.2 11.2  5.2  7.0 16.5 16.5 15.2 17.3 22.5 17.3 13.6 14.5 18.8 15.5 23.6 18.5 33.9 25.5 26.4 32.5 26.7 21.5 23.3 29.5</code></pre>
<pre class="r"><code># extracts the `len` variable/column, where `supp` is &#39;VC&#39;

# Alternative 1
# Pipe operator shortcut: Ctrl + Shift + M
dat %&gt;% 
  filter(supp == &quot;VC&quot;) %&gt;% 
  select(len)</code></pre>
<pre><code>##     len
## 1   4.2
## 2  11.5
## 3   7.3
## 4   5.8
## 5   6.4
## 6  10.0
## 7  11.2
## 8  11.2
## 9   5.2
## 10  7.0
## 11 16.5
## 12 16.5
## 13 15.2
## 14 17.3
## 15 22.5
## 16 17.3
## 17 13.6
## 18 14.5
## 19 18.8
## 20 15.5
## 21 23.6
## 22 18.5
## 23 33.9
## 24 25.5
## 25 26.4
## 26 32.5
## 27 26.7
## 28 21.5
## 29 23.3
## 30 29.5</code></pre>
<pre class="r"><code># Alternative 2
# This is basically Alternative 1 without the pipe operator
select(filter(dat, supp == &quot;VC&quot;), len)</code></pre>
<pre><code>##     len
## 1   4.2
## 2  11.5
## 3   7.3
## 4   5.8
## 5   6.4
## 6  10.0
## 7  11.2
## 8  11.2
## 9   5.2
## 10  7.0
## 11 16.5
## 12 16.5
## 13 15.2
## 14 17.3
## 15 22.5
## 16 17.3
## 17 13.6
## 18 14.5
## 19 18.8
## 20 15.5
## 21 23.6
## 22 18.5
## 23 33.9
## 24 25.5
## 25 26.4
## 26 32.5
## 27 26.7
## 28 21.5
## 29 23.3
## 30 29.5</code></pre>
<pre class="r"><code># Below we can also extract the other 2 columns
dat[dat$supp==&#39;VC&#39;, 2]</code></pre>
<pre><code>##  [1] VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC
## Levels: OJ VC</code></pre>
<pre class="r"><code>dat[dat$supp==&#39;VC&#39;, 3]</code></pre>
<pre><code>##  [1] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0</code></pre>
</div>
<div id="formulating-a-question" class="section level2">
<h2>4. Formulating a Question</h2>
<p>After examining the data set, what are some study questions we can
ask? Make some suggestions in the Teams chat!</p>
<p>Below are some questions suggested by students in the chat: * Does
dosage and length have a positive correlation? * Which vitamin
contributes to the most growth?</p>
</div>
<div id="calculations-in-r" class="section level2">
<h2>5. Calculations in R</h2>
<p>Find the (sample) mean and standard deviation of tooth length in the
Vitamin C group and again in the group that only received Orange Juice.
What can be said based on the numbers computed about the differences
between the two groups?</p>
<p>Do this using the formula, instead of the functions
<code>mean()</code> or <code>sd()</code> to practice using R as a
calculator!</p>
<pre class="r"><code># Task for students: try to recreate the mean and variance values through
# Calculations in R, and compare them with the values you should get through
# mean() and sd() commands in R

# Create tooth length variable for the vitamin C 
vc &lt;- dat[dat$supp==&#39;VC&#39;, 1]

# take the sum of the tooth length, then divide by the number of values
n &lt;- length(vc)
mean.vc &lt;- sum(vc)/n
mean.vc</code></pre>
<pre><code>## [1] 16.96333</code></pre>
<pre class="r"><code># Can also compute using a for loop
mean.vc2 &lt;- 0
for (i in 1:n){
  mean.vc2 &lt;- mean.vc2 + vc[i]/n
}
mean.vc2</code></pre>
<pre><code>## [1] 16.96333</code></pre>
<pre class="r"><code># Compare to mean() function
mean(vc)</code></pre>
<pre><code>## [1] 16.96333</code></pre>
<pre class="r"><code># Standard deviation
var.vc &lt;- sum((vc - mean.vc)^2)/(n-1)
sd.vc &lt;- sqrt(var.vc)
sd.vc</code></pre>
<pre><code>## [1] 8.266029</code></pre>
<pre class="r"><code># Compare to sd() function
sd(vc)</code></pre>
<pre><code>## [1] 8.266029</code></pre>
<p>Below is a repeat of the above but for <code>OJ</code> (orange
juice):</p>
<pre class="r"><code># Orange Juice
oj &lt;- dat[dat$supp==&#39;OJ&#39;, 1]

# Mean
n &lt;- length(oj)
mean.oj &lt;- sum(oj)/n
mean.oj</code></pre>
<pre><code>## [1] 20.66333</code></pre>
<pre class="r"><code># Can also compute using a for loop
mean.oj2 &lt;- 0
for (i in 1:n){
  mean.oj2 &lt;- mean.oj2 + oj[i]/n
}
mean.oj2</code></pre>
<pre><code>## [1] 20.66333</code></pre>
<pre class="r"><code># Compare to mean()
mean(oj)</code></pre>
<pre><code>## [1] 20.66333</code></pre>
<pre class="r"><code># Standard deviation
var.oj &lt;- sum((oj - mean.oj)^2)/(n-1)
sd.oj &lt;- sqrt(var.oj)
sd.oj</code></pre>
<pre><code>## [1] 6.605561</code></pre>
<pre class="r"><code># Compare to sd()
sd(oj)</code></pre>
<pre><code>## [1] 6.605561</code></pre>
<p>Trying to type the variance formula in plain-text is not visually
appealing, nor helpful in communicating (it’s very difficult to read!).
The beauty of LaTeX is the format is fairly intuitive, such as
<code>$\frac{numerator}{denominator}$</code> will render as <span
class="math inline">\(\frac{numerator}{denominator}\)</span> (the dollar
signs indicate the start and end of the math setting, double-dollar sign
will have the math rendered centre to the page). For example, the sample
variance can be written as:</p>
<p><span class="math display">\[s^2 = \frac{\sum_{i=1}^n (x_i -
\bar{x})^2}{n-1}\]</span> Try to write the sample mean in LaTeX and
quote the values computed in the R chunk above!</p>
<p>For the mean we can use
<code>\bar{x}_n = \frac{\sum_{i=1}^n x_i}{n}</code>: <span
class="math display">\[\bar{x}_n = \frac{\sum_{i=1}^n
x_i}{n}\]</span></p>
</div>
<div id="simple-plots" class="section level2">
<h2>6. Simple Plots</h2>
<p>Numerical summaries can be powerful to provide concrete, numerical
evidence to support our claims. Using graphical displays can also
communicate clearly in a visual manner the story that our numbers tell,
and can sometimes be a more powerful communication tool than numbers
because we can <em>see</em> the <em>scale</em> of differences. Let’s use
the <code>ggplot</code> package in <code>tidyverse</code> to produce
side-by-side box plots of how tooth length growth differs between the
two sources of vitamin C:</p>
<pre class="r"><code># Focus of this segment: understanding the layering language of ggplot
# Note also the R chunk options that control the alignment and size of
# The output figures

dat %&gt;% 
  ggplot(aes(x = supp, y = len)) +
  geom_boxplot() + # passing aes(x,y) into here works too!
  labs(title = &quot;Guinea Pig Tooth Length Growth by Vitamin C Source&quot;,
       subtitle = &quot;ToothGrowth Dataset&quot;,
       x = &quot;Vitamin C Source&quot;,
       y = &quot;Tooth Length Growth&quot;) +
  scale_x_discrete(labels = c(&quot;Orange Juice&quot;, &quot;Ascorbic Acid&quot;)) +
  theme_bw() # there are many different themes from which to choose!</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>What can we notice about tooth length growth between the two
supplement groups?</p>
<p>Practice using visual and numeric features to:</p>
<ol style="list-style-type: decimal">
<li>Write a conclusion about any perceivable differences between the two
sources of vitamin C.</li>
<li>Provide graphical and numerical features and their <span
style="text-decoration:underline">interpretations</span>, explaining how
they support your claim(s)!</li>
</ol>
<p>Here are things that we notice:</p>
<ul>
<li>The median tooth length growth for the orange juice supplement is
almost at same level as the third quartile of tooth length growth for
ascorbic acid.<br />
</li>
<li>There is some evidence which suggests that median tooth length
growth for the orange juice supplement is statistically significantly
larger than for the ascorbic acid supplement.</li>
<li>We can use a t-test to test for the difference in means between two
groups. This is just a quick example but make sure to check the
assumptions before proceeding!</li>
</ul>
<pre class="r"><code># Two-sided t-test
t.test(oj,vc)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  oj and vc
## t = 1.9153, df = 55.309, p-value = 0.06063
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.1710156  7.5710156
## sample estimates:
## mean of x mean of y 
##  20.66333  16.96333</code></pre>
<pre class="r"><code># One-sided t-test
t.test(oj,vc,&quot;greater&quot;)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  oj and vc
## t = 1.9153, df = 55.309, p-value = 0.03032
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  0.4682687       Inf
## sample estimates:
## mean of x mean of y 
##  20.66333  16.96333</code></pre>
<ul>
<li>From the two-sided t-test (p-value = 0.06), there is some evidence
to suggest that the difference in tooth length growth between the two
supplement groups is statistically significant.</li>
<li>From the one-sided t-test (p-value = 0.03), there is evidence to
suggest that the mean tooth length growth for guinea pigs with orange
juice supplements is statistically significantly greater than the mean
tooth length growth for guinea pigs with ascorbic acid supplements.</li>
<li>Note that the p-value for the one-sided t-test is half the p-value
for the two-sided t-test.</li>
</ul>
</div>
</div>
<div id="lab-1" class="section level1">
<h1>Lab 1</h1>
<p>In this R Lab, you will be guided by the TA to demonstrate the steps
involved in performing an exploratory data analysis.</p>
<div id="r-lab-learning-goals-1" class="section level2">
<h2>R Lab Learning Goals</h2>
<ul>
<li>Load data from a local csv file</li>
<li>Formulate a question for EDA</li>
<li>Examine and pre-process your data using functions from the
<code>tidyverse</code> package</li>
<li>Use the <code>lubridate</code> package for manipulating dates</li>
<li>Produce numerical summaries using the <code>summarize</code>
function</li>
<li>Produce plots in ggplot to explore your EDA question</li>
</ul>
<pre class="r"><code># Load Required Packages
library(tidyverse)
library(lubridate)

# Set work directory
setwd(&quot;~/GitHub/dang-kevin.github.io/STA238&quot;)

# Read in Data
weather &lt;- read.csv(&quot;weatherstats_vancouver_daily.csv&quot;)

# Using file.choose() allows you to manually select the file you want
# weather &lt;- read.csv(file.choose())

# Quick overview of the data
glimpse(weather)</code></pre>
<pre><code>## Rows: 1,000
## Columns: 71
## $ X                             &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, …
## $ date                          &lt;chr&gt; &quot;2022-01-16&quot;, &quot;2022-01-15&quot;, &quot;2022-01-14&quot;, &quot;2022-01-13&quot;, &quot;2022-01-12&quot;, &quot;2022-01-11&quot;, &quot;2022-01-10&quot;, &quot;2022-01-09&quot;, &quot;2022-01-08&quot;, &quot;2022-01-…
## $ max_temperature               &lt;dbl&gt; 6.3, 7.0, 9.8, 11.1, 11.5, 10.0, 8.5, 6.7, 3.4, 4.6, 3.9, 0.8, 4.9, 5.4, 5.0, 1.4, -2.5, -0.7, -4.1, -4.4, -7.8, -5.7, 0.6, 3.6, 7.0, 8…
## $ avg_hourly_temperature        &lt;dbl&gt; 5.29, 5.66, 6.94, 7.56, 9.87, 8.97, 4.78, 2.55, 1.52, 2.64, 0.80, -1.56, 2.12, 3.35, 3.31, -2.01, -6.64, -4.03, -7.09, -8.05, -10.80, -…
## $ avg_temperature               &lt;dbl&gt; 5.55, 5.15, 7.45, 7.50, 10.19, 8.35, 3.55, 2.60, 0.64, 2.95, 0.19, -1.29, 2.55, 3.50, 2.75, -4.20, -6.70, -4.39, -7.90, -8.60, -11.55, …
## $ min_temperature               &lt;dbl&gt; 4.8, 3.3, 5.1, 3.9, 8.9, 6.7, -1.4, -1.5, -2.1, 1.3, -3.5, -3.4, 0.2, 1.6, 0.5, -9.8, -10.9, -8.1, -11.7, -12.8, -15.3, -10.8, -5.8, 0.…
## $ max_humidex                   &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ min_windchill                 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, -2, -5, NA, -7, -10, NA, NA, NA, -13, -17, -14, -18, -20, -23, -16, -13, NA, NA, NA, -10, -7, -5, NA, -6, -…
## $ max_relative_humidity         &lt;int&gt; 100, 100, 99, 99, 99, 99, 99, 99, 96, 99, 99, 98, 99, 96, 96, 82, 93, 94, 92, 91, 85, 90, 95, 98, 96, 98, 99, 93, 99, 98, 97, 95, 91, 9…
## $ avg_hourly_relative_humidity  &lt;dbl&gt; 99.0, 99.2, 95.7, 94.8, 96.8, 96.3, 93.4, 93.7, 87.3, 77.5, 98.0, 90.9, 90.2, 87.3, 84.6, 71.9, 74.8, 85.0, 69.2, 80.9, 67.9, 72.5, 87.…
## $ avg_relative_humidity         &lt;dbl&gt; NA, 99.0, 93.0, 93.0, 94.5, 95.5, 91.5, 91.5, 79.0, 78.5, 98.0, NA, 85.0, 84.5, 82.0, 70.5, 72.5, 80.0, 70.0, 79.0, 71.0, 72.5, 84.0, 9…
## $ min_relative_humidity         &lt;int&gt; 97, 98, 87, 87, 90, 92, 84, 84, 62, 58, 97, 82, 71, 73, 68, 59, 52, 66, 48, 67, 57, 55, 73, 91, 72, 83, 68, 61, 72, 66, 81, 70, 62, 83,…
## $ max_dew_point                 &lt;dbl&gt; 6.1, 6.5, 7.4, 8.5, 10.2, 9.4, 6.9, 3.6, 2.4, 3.8, 3.9, 0.2, 1.6, 3.1, 2.8, -3.4, -7.3, -4.3, -6.2, -8.9, -10.6, -8.2, -0.4, 2.0, 4.0, …
## $ avg_hourly_dew_point          &lt;dbl&gt; 5.1, 5.6, 6.3, 6.7, 9.4, 8.4, 3.8, 1.6, -0.5, -1.1, 0.5, -2.9, 0.6, 1.4, 0.9, -6.5, -10.7, -6.3, -12.1, -10.8, -15.7, -11.9, -4.7, 0.7,…
## $ avg_dew_point                 &lt;dbl&gt; 5.3, 4.8, 6.3, 6.2, 9.2, 8.1, 3.4, 1.6, -1.0, -0.6, 0.5, -2.2, 0.5, 1.2, 0.4, -6.2, -10.1, -7.1, -11.1, -11.6, -15.0, -11.9, -4.5, 1.0,…
## $ min_dew_point                 &lt;dbl&gt; 4.6, 3.1, 5.3, 4.0, 8.2, 6.8, -0.1, -0.5, -4.5, -5.1, -2.9, -4.6, -0.6, -0.6, -1.9, -9.1, -12.8, -9.9, -16.0, -14.3, -19.4, -15.6, -8.5…
## $ max_wind_speed                &lt;int&gt; 11, 13, 14, 16, 23, 28, 28, 15, 24, 61, 26, 23, 31, 36, 44, 36, 18, 25, 23, 17, 21, 19, 32, 26, 31, 32, 20, 15, 24, 35, 27, 36, 26, 22,…
## $ avg_hourly_wind_speed         &lt;dbl&gt; 4.96, 6.21, 7.67, 8.58, 15.88, 20.58, 15.42, 7.08, 14.21, 34.17, 16.83, 13.12, 16.38, 22.42, 30.17, 19.33, 9.96, 12.38, 14.17, 9.12, 15…
## $ avg_wind_speed                &lt;dbl&gt; 6.0, 8.0, 8.0, 9.0, 14.5, 21.0, 15.0, 8.0, 14.5, 34.0, 15.0, 15.0, 16.5, 23.0, 32.5, 24.0, 9.5, 15.0, 14.0, 10.0, 12.5, 15.5, 22.0, 15.…
## $ min_wind_speed                &lt;int&gt; 1, 3, 2, 2, 6, 14, 2, 1, 5, 7, 4, 7, 2, 10, 21, 12, 1, 5, 5, 3, 4, 12, 12, 4, 8, 9, 1, 1, 1, 4, 6, 1, 2, 6, 4, 7, 7, 1, 3, 2, 3, 1, 3, …
## $ max_wind_gust                 &lt;int&gt; NA, NA, NA, NA, 38, 41, 38, NA, 32, 83, 38, NA, 46, 62, 68, 49, NA, 32, 32, NA, NA, NA, 42, 39, 46, 46, NA, NA, 31, 46, 31, 47, 47, 38,…
## $ wind_gust_dir_10s             &lt;int&gt; NA, NA, NA, NA, 9, 10, 7, NA, 7, 29, 10, NA, 20, 20, 14, 9, NA, 7, 6, NA, NA, NA, 9, 10, 26, 14, NA, NA, 31, 20, 9, 29, 7, 9, 8, 16, 16…
## $ max_pressure_sea              &lt;dbl&gt; 102.76, 102.90, 103.29, 103.06, 101.97, 102.24, 102.69, 102.79, 102.71, 101.45, 101.05, 102.52, 101.75, 100.67, 101.16, 102.51, 102.41,…
## $ avg_hourly_pressure_sea       &lt;dbl&gt; 102.34, 102.82, 103.10, 102.30, 101.77, 101.94, 102.49, 102.65, 102.25, 99.95, 100.12, 102.08, 101.31, 99.77, 100.39, 102.10, 101.90, 1…
## $ avg_pressure_sea              &lt;dbl&gt; 102.35, 102.81, 103.06, 102.37, 101.81, 101.95, 102.38, 102.67, 102.12, 100.22, 100.04, 101.87, 101.25, 99.99, 100.27, 101.81, 101.78, …
## $ min_pressure_sea              &lt;dbl&gt; 101.94, 102.71, 102.83, 101.68, 101.64, 101.66, 102.06, 102.54, 101.53, 99.00, 99.03, 101.22, 100.75, 99.32, 99.37, 101.11, 101.14, 100…
## $ max_pressure_station          &lt;dbl&gt; 102.71, 102.85, 103.24, 103.01, 101.92, 102.19, 102.64, 102.74, 102.66, 101.40, 101.00, 102.47, 101.70, 100.62, 101.11, 102.46, 102.36,…
## $ avg_hourly_pressure_station   &lt;dbl&gt; 102.29, 102.77, 103.05, 102.25, 101.72, 101.89, 102.44, 102.60, 102.20, 99.90, 100.07, 102.03, 101.26, 99.72, 100.34, 102.05, 101.85, 1…
## $ avg_pressure_station          &lt;dbl&gt; 102.30, 102.76, 103.01, 102.32, 101.75, 101.90, 102.33, 102.61, 102.07, 100.17, 99.99, 101.82, 101.20, 99.94, 100.22, 101.76, 101.72, 1…
## $ min_pressure_station          &lt;dbl&gt; 101.89, 102.66, 102.78, 101.63, 101.59, 101.61, 102.01, 102.49, 101.48, 98.95, 98.98, 101.17, 100.70, 99.27, 99.32, 101.06, 101.09, 100…
## $ max_visibility                &lt;int&gt; 16100, 24100, 48300, 48300, 32200, 32200, 32200, 40200, 48300, 48300, 24100, 32200, 40200, 32200, 48300, 48300, 48300, 40200, 40200, 40…
## $ avg_hourly_visibility         &lt;dbl&gt; 6950.0, 10870.8, 31570.8, 34525.0, 17116.7, 24008.3, 24812.5, 30837.5, 23845.8, 36287.5, 10545.8, 19091.7, 19437.5, 29579.2, 26158.3, 3…
## $ avg_visibility                &lt;int&gt; 8350, 12150, 33800, 36200, 19300, 18500, 22550, 20600, 26150, 28200, 12350, 16400, 22500, 20950, 26550, 36200, 36200, 20500, 20300, 321…
## $ min_visibility                &lt;int&gt; 600, 200, 19300, 24100, 6400, 4800, 12900, 1000, 4000, 8100, 600, 600, 4800, 9700, 4800, 24100, 24100, 800, 400, 24100, 4800, 2400, 120…
## $ max_health_index              &lt;dbl&gt; 2.0, 2.2, 1.8, 2.3, 2.4, 2.3, 2.8, 3.0, 2.9, 2.8, 2.5, 3.2, 2.9, 2.5, 2.4, 3.2, 4.1, 3.6, 3.4, 3.9, 2.8, 2.4, 2.3, 2.3, 2.9, 2.4, 3.8, …
## $ avg_hourly_health_index       &lt;dbl&gt; 1.3, 1.5, 1.3, 1.7, 1.7, 1.8, 2.1, 2.0, 2.2, 2.2, 2.1, 2.2, 2.2, 2.2, 2.0, 2.3, 2.6, 2.5, 2.6, 2.6, 2.3, 2.0, 1.9, 1.9, 2.2, 1.9, 2.5, …
## $ avg_health_index              &lt;dbl&gt; 1.5, 1.6, 1.4, 1.6, 1.8, 1.8, 2.2, 2.2, 2.2, 2.2, 2.1, 2.5, 2.4, 2.2, 2.0, 2.1, 3.1, 2.7, 2.7, 3.0, 2.4, 2.1, 2.0, 2.0, 2.3, 1.8, 2.8, …
## $ min_health_index              &lt;dbl&gt; 1.0, 1.0, 1.0, 1.0, 1.2, 1.3, 1.7, 1.5, 1.6, 1.6, 1.8, 1.7, 1.8, 1.9, 1.7, 1.0, 2.1, 1.8, 2.0, 2.0, 2.0, 1.8, 1.7, 1.6, 1.7, 1.2, 1.7, …
## $ heatdegdays                   &lt;dbl&gt; 12.4, 12.8, 10.6, 10.5, 7.8, 9.7, 14.4, 15.4, 17.4, 15.1, 17.8, 19.3, 15.4, 14.5, 15.2, 22.2, 24.7, 22.4, 25.9, 26.6, 29.6, 26.2, 20.6,…
## $ cooldegdays                   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
## $ growdegdays_5                 &lt;dbl&gt; 0.6, 0.2, 2.5, 2.5, 5.2, 3.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, …
## $ growdegdays_7                 &lt;dbl&gt; 0.0, 0.0, 0.4, 0.5, 3.2, 1.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, …
## $ growdegdays_10                &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, …
## $ precipitation                 &lt;dbl&gt; 0.0, 0.2, 0.0, 0.2, 29.3, 17.7, 4.6, 0.0, 3.0, 7.6, 16.4, 0.9, 7.0, 7.6, 8.6, 0.0, 0.0, 4.7, 0.0, 0.0, 0.8, 3.0, 1.6, 8.7, 2.4, 3.4, 6.…
## $ rain                          &lt;dbl&gt; NA, 0.2, 0.0, 0.2, 29.3, 17.7, 4.6, 0.0, 3.0, 7.6, 6.8, NA, 5.6, 7.6, 4.9, 0.0, 0.0, NA, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1, 2.4, 3.4, 6.5, 0…
## $ snow                          &lt;dbl&gt; NA, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, NA, 0.4, 0.0, 3.7, 0.0, 0.0, 2.0, 0.2, 0.0, 1.0, 4.0, 2.2, 6.9, 0.0, 0.0, 0.0, 0…
## $ snow_on_ground                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 12, 0, 0, 2, 7, NA, NA, 16, 3, 1, 1, 2, 0, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ sunrise                       &lt;chr&gt; &quot;08:01:00&quot;, &quot;08:02:00&quot;, &quot;08:03:00&quot;, &quot;08:04:00&quot;, &quot;08:04:00&quot;, &quot;08:05:00&quot;, &quot;08:05:00&quot;, &quot;08:06:00&quot;, &quot;08:06:00&quot;, &quot;08:07:00&quot;, &quot;08:07:00&quot;, &quot;08…
## $ sunset                        &lt;chr&gt; &quot;16:43:00&quot;, &quot;16:42:00&quot;, &quot;16:40:00&quot;, &quot;16:39:00&quot;, &quot;16:38:00&quot;, &quot;16:36:00&quot;, &quot;16:35:00&quot;, &quot;16:34:00&quot;, &quot;16:32:00&quot;, &quot;16:31:00&quot;, &quot;16:30:00&quot;, &quot;16…
## $ daylight                      &lt;dbl&gt; 8.70, 8.67, 8.62, 8.58, 8.57, 8.52, 8.50, 8.47, 8.43, 8.40, 8.38, 8.37, 8.35, 8.32, 8.30, 8.28, 8.27, 8.25, 8.23, 8.23, 8.22, 8.22, 8.2…
## $ sunrise_f                     &lt;dbl&gt; 8.02, 8.03, 8.05, 8.07, 8.07, 8.08, 8.08, 8.10, 8.10, 8.12, 8.12, 8.12, 8.12, 8.13, 8.13, 8.13, 8.13, 8.13, 8.13, 8.12, 8.12, 8.12, 8.1…
## $ sunset_f                      &lt;dbl&gt; 16.72, 16.70, 16.67, 16.65, 16.63, 16.60, 16.58, 16.57, 16.53, 16.52, 16.50, 16.48, 16.47, 16.45, 16.43, 16.42, 16.40, 16.38, 16.37, 16…
## $ min_uv_forecast               &lt;int&gt; 1, NA, 1, 1, NA, NA, NA, 1, NA, 1, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1, 1, NA, NA, NA, NA, NA, NA, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ max_uv_forecast               &lt;int&gt; 1, NA, 1, 1, NA, NA, NA, 1, NA, 1, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1, 1, NA, NA, NA, NA, NA, NA, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ min_high_temperature_forecast &lt;int&gt; 7, 7, 9, 9, 10, 10, 8, 6, 2, 3, 3, 2, 3, 2, 5, -1, -3, -1, -6, -5, -9, -4, 0, 3, 4, 8, 1, 1, 5, 6, 2, 5, 6, 3, 3, 4, 6, 6, 5, 7, 6, 3, …
## $ max_high_temperature_forecast &lt;int&gt; 7, 8, 9, 10, 10, 10, 8, 6, 3, 3, 3, 2, 4, 4, 5, -1, -2, -1, -5, -4, -8, -4, 1, 3, 5, 8, 1, 1, 5, 6, 3, 6, 6, 5, 5, 5, 6, 6, 5, 7, 6, 3,…
## $ min_low_temperature_forecast  &lt;int&gt; 4, 5, 6, 6, 9, 6, 7, 0, 2, -1, 4, -2, -2, 1, 3, 0, -9, -8, -8, -10, -9, -11, -6, -1, 0, 2, 2, -5, -3, 3, 1, -2, 2, 2, 1, 2, 1, 6, 1, 1,…
## $ max_low_temperature_forecast  &lt;int&gt; 4, 5, 6, 6, 9, 9, 8, 0, 4, -1, 4, 0, -2, 1, 3, 0, -7, -7, -4, -10, -7, -10, -6, 0, 1, 3, 2, -4, -3, 3, 1, 1, 3, 2, 1, 2, 1, 6, 1, 2, 6,…
## $ solar_radiation               &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ max_cloud_cover_4             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ avg_hourly_cloud_cover_4      &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ avg_cloud_cover_4             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ min_cloud_cover_4             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ max_cloud_cover_8             &lt;int&gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, …
## $ avg_hourly_cloud_cover_8      &lt;dbl&gt; 6.7, 6.3, 8.0, 6.2, 7.9, 8.0, 6.9, 2.6, 7.6, 6.5, 7.9, 7.3, 7.5, 7.8, 8.0, 7.9, 3.5, 4.6, 4.6, 5.3, 6.1, 6.7, 7.1, 7.5, 7.5, 7.9, 5.7, …
## $ avg_cloud_cover_8             &lt;dbl&gt; 5.0, 4.5, 8.0, 4.5, 7.5, 8.0, 4.0, 4.0, 7.0, 4.5, 6.5, 5.0, 5.5, 7.0, 8.0, 7.0, 4.5, 4.5, 4.0, 4.0, 4.0, 4.5, 5.0, 4.5, 6.0, 7.5, 4.0, …
## $ min_cloud_cover_8             &lt;int&gt; 2, 1, 8, 1, 7, 8, 0, 0, 6, 1, 5, 2, 3, 6, 8, 6, 1, 1, 0, 0, 0, 1, 2, 1, 4, 7, 0, 0, 0, 2, 2, 1, 7, 1, 7, 5, 2, 3, 2, 2, 8, 5, 0, 0, 0, …
## $ max_cloud_cover_10            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ avg_hourly_cloud_cover_10     &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ avg_cloud_cover_10            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ min_cloud_cover_10            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…</code></pre>
<p>Note that since this data is from a csv file, functions like
<code>?weather</code> will not provide us with information about the
data set. For the purposes of this lab, we assume that the variable
names are sufficiently informative to intuit their contents. In
practice, however, information about the data and its variables can be
found in a documentation file that is usually available from the source
of the data.</p>
</div>
<div id="formulating-questions-for-eda" class="section level2">
<h2>1. Formulating questions for EDA</h2>
<p>Our goal during exploratory data analysis (EDA) is to develop an
understanding of our data. Real data is complicated, often containing
missing data and irregular formatting.</p>
<p>In this lab, we will demonstrate this process with the question:
<strong>“What is the monthly total rainfall in Vancouver over
2021?”</strong></p>
</div>
<div id="checking-the-rain-variable" class="section level2">
<h2>2. Checking the <code>rain</code> variable</h2>
<p>The variable <code>rain</code> contains the daily rainfall measured
in millimeters. Our first task is to check for any missing data. We
could do this using the base R commands from Lab 0, but the code gets
messy for complicated manipulations. Instead, we will use the pipe
operator <code>%&gt;%</code> from the <code>tidyverse</code> package
along with some data processing functions. The pipe operator
<code>%&gt;%</code> allows us to take the output from one function and
“pipe it in” to the argument of the next function. You will find that
data manipulations using the pipe operator are much more readable than
the equivalents in base R!</p>
<pre class="r"><code># Examples of pipe operator

#1. Pulling the first 5 rows of data containing date, rain, and average dew point

# Tidyverse way
weather %&gt;% 
  select(date, rain, avg_dew_point) %&gt;%
  head(5)</code></pre>
<pre><code>##         date rain avg_dew_point
## 1 2022-01-16   NA           5.3
## 2 2022-01-15  0.2           4.8
## 3 2022-01-14  0.0           6.3
## 4 2022-01-13  0.2           6.2
## 5 2022-01-12 29.3           9.2</code></pre>
<pre class="r"><code># base R way
head(weather[c(&quot;date&quot;, &quot;rain&quot;,&quot;avg_dew_point&quot;)], 5)</code></pre>
<pre><code>##         date rain avg_dew_point
## 1 2022-01-16   NA           5.3
## 2 2022-01-15  0.2           4.8
## 3 2022-01-14  0.0           6.3
## 4 2022-01-13  0.2           6.2
## 5 2022-01-12 29.3           9.2</code></pre>
<pre class="r"><code># head(weather[, c(&quot;date&quot;, &quot;rain&quot;,&quot;avg_dew_point&quot;)], 5)

#2. Adding new columns of data to the existing weather data:

# Tidyverse way
weather &lt;- weather %&gt;% 
  mutate(new_variable_1 = 1.5 * avg_hourly_temperature,
         new_variable_2 = rain + 10)

# base R way
weather$new_variable_1 &lt;- 1.5 * weather$avg_hourly_temperature
weather$new_variable_2 &lt;- weather$rain + 10</code></pre>
<p>First we will check which dates have missing rainfall data:</p>
<pre class="r"><code># Base R way
weather$date[is.na(weather$rain)]</code></pre>
<pre><code>##  [1] &quot;2022-01-16&quot; &quot;2022-01-05&quot; &quot;2021-12-30&quot; &quot;2020-12-08&quot; &quot;2020-12-07&quot; &quot;2020-12-06&quot; &quot;2020-12-05&quot; &quot;2020-12-04&quot; &quot;2020-12-03&quot; &quot;2020-12-02&quot; &quot;2020-12-01&quot;</code></pre>
<pre class="r"><code># Tidyverse way
weather %&gt;% 
  filter(is.na(rain)) %&gt;% 
  # can also use select(date)
  pull(date)</code></pre>
<pre><code>##  [1] &quot;2022-01-16&quot; &quot;2022-01-05&quot; &quot;2021-12-30&quot; &quot;2020-12-08&quot; &quot;2020-12-07&quot; &quot;2020-12-06&quot; &quot;2020-12-05&quot; &quot;2020-12-04&quot; &quot;2020-12-03&quot; &quot;2020-12-02&quot; &quot;2020-12-01&quot;</code></pre>
<pre class="r"><code># To show the days that DO NOT have missing rain values, add &#39;!&#39; in front of is.na()
# e.g. weather$date[!is.na(weather$rain)]</code></pre>
<p>We see that there is one missing value of rainfall in the year 2021.
This might be a cause for concern if this was a day with particularly
high rainfall. Unfortunately, we do not know if this was the case. The
best we can do in these situations is to tell the reader that what is
missing from our data so that they are aware of the limitations of our
analysis.</p>
</div>
<div id="formatting-the-date-variable" class="section level2">
<h2>3. Formatting the <code>date</code> variable</h2>
<p>Since we are concerned with total monthly rainfall, our next task is
to convert the <code>date</code> variable into a form that is amenable
to analysis. First we examine the format <code>date</code>:</p>
<pre class="r"><code># str() compactly displays the structure of an object
# Good alternative to glimpse()
str(weather$date)</code></pre>
<pre><code>##  chr [1:1000] &quot;2022-01-16&quot; &quot;2022-01-15&quot; &quot;2022-01-14&quot; &quot;2022-01-13&quot; &quot;2022-01-12&quot; &quot;2022-01-11&quot; &quot;2022-01-10&quot; &quot;2022-01-09&quot; &quot;2022-01-08&quot; &quot;2022-01-07&quot; &quot;2022-01-06&quot; &quot;2022-01-05&quot; ...</code></pre>
<p>We find that each entry of <code>date</code> is a character vector of
the form “YYYY-MM-DD”. To prepare this data for use in
<code>lubridate</code>, we convert <code>date</code> from a character
vector to a datetime object.</p>
<pre class="r"><code># First we convert date to a datetime object
# To explain format, look at `?strptime`

# The base R way
weather$date &lt;- as.Date(weather$date, format = &quot;%Y-%m-%d&quot;)

# The tidyverse way using mutate()
# Make sure to reassign the dataset to ensure that the mutation step is saved
weather &lt;- weather %&gt;% 
  mutate(date = as.Date(date, format = &quot;%Y-%m-%d&quot;))</code></pre>
<p>Now that we have a datetime object, we can use functions from
<code>lubridate</code> to easily convert <code>date</code> into many
useful quantities. We use the functions <code>year</code>,
<code>month</code>, and <code>day</code> to define the corresponding
variables in our data</p>
<pre class="r"><code># Demonstrate some lubridate functions

# Extract weekday as character
weekdays(weather$date) %&gt;% str()</code></pre>
<pre><code>##  chr [1:1000] &quot;Sunday&quot; &quot;Saturday&quot; &quot;Friday&quot; &quot;Thursday&quot; &quot;Wednesday&quot; &quot;Tuesday&quot; &quot;Monday&quot; &quot;Sunday&quot; &quot;Saturday&quot; &quot;Friday&quot; &quot;Thursday&quot; &quot;Wednesday&quot; &quot;Tuesday&quot; &quot;Monday&quot; &quot;Sunday&quot; ...</code></pre>
<pre class="r"><code># Extract month as integer
lubridate::month(weather$date) %&gt;% str()</code></pre>
<pre><code>##  num [1:1000] 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<pre class="r"><code># Extract month as ordered factor
month(weather$date, label = TRUE) %&gt;% str()</code></pre>
<pre><code>##  Ord.factor w/ 12 levels &quot;Jan&quot;&lt;&quot;Feb&quot;&lt;&quot;Mar&quot;&lt;..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<pre class="r"><code># Extract the year as integer
year(weather$date) %&gt;% str()</code></pre>
<pre><code>##  num [1:1000] 2022 2022 2022 2022 2022 ...</code></pre>
<pre class="r"><code># summarizing the pieces above
# Create the year, month, and day variables
weather &lt;- weather %&gt;%
  mutate(year = year(date),
         month = month(date, label = TRUE),
         day = day(date))</code></pre>
</div>
<div id="filtering-and-summarizing-the-data" class="section level2">
<h2>4. Filtering and summarizing the data</h2>
<p>Now that we have examined and processed our data, we can start to
answer our original question: “What is the monthly total rainfall in
Vancouver over 2021?” To begin, we might use <code>filter</code> and
<code>select</code> to inspect our data</p>
<pre class="r"><code>weather %&gt;% 
  filter(year == 2021) %&gt;% 
  select(year, month, day, rain) %&gt;% 
  head(10)</code></pre>
<pre><code>##    year month day rain
## 1  2021   Dec  31  0.0
## 2  2021   Dec  30   NA
## 3  2021   Dec  29  0.0
## 4  2021   Dec  28  0.0
## 5  2021   Dec  27  0.0
## 6  2021   Dec  26  0.0
## 7  2021   Dec  25  0.0
## 8  2021   Dec  24  5.1
## 9  2021   Dec  23  2.4
## 10 2021   Dec  22  3.4</code></pre>
<p>This output, however, is not as helpful as a numerical summary of the
data. The function <code>group_by</code> and <code>summarize</code>
provide a useful method for summarizing the data. First we choose a
variable(s) to group by and then we define the numerical summaries we
wish to compute. For example, we might be interested in the mean and the
maximum rainfall each month.</p>
<pre class="r"><code># Assign to new dataframe to use for plotting
df &lt;- weather %&gt;% 
  filter(year == 2021) %&gt;% 
  group_by(month) %&gt;% 
  summarise(rain_tot = sum(rain, na.rm = T),
            rain_max = max(rain, na.rm = T))

df</code></pre>
<pre><code>## # A tibble: 12 × 3
##    month rain_tot rain_max
##    &lt;ord&gt;    &lt;dbl&gt;    &lt;dbl&gt;
##  1 Jan      176.      29.5
##  2 Feb       75       19.2
##  3 Mar       34        6  
##  4 Apr       38       13.5
##  5 May       30.2      8.2
##  6 Jun       37.2     12.5
##  7 Jul        0        0  
##  8 Aug       36.7     22.1
##  9 Sep      155       50.9
## 10 Oct      148.      43.3
## 11 Nov      312.      52.5
## 12 Dec       93.5     31.3</code></pre>
<p>These numerical summaries may be useful in some contexts, but a graph
is generally better for examining these summaries. Thankfully, the
results of the summary can easily be piped into ggplot to make such
graphs!</p>
<pre class="r"><code>df %&gt;% 
  ggplot(aes(x = month, y = rain_tot)) +
  geom_col(fill = &quot;skyblue&quot;) +
  labs(title = &quot;Total monthly rainfall, Vancouver 2021&quot;,
       x = &quot;Month&quot;,
       y = &quot;Total rainfall (mm)&quot;) +
  # Alternative labelling method instead of labs()
  # ggtitle(&quot;Total monthly rainfall, Vancouver 2021&quot;) +
  # xlab(&quot;Month&quot;) +
  # ylab(&quot;Total rainfall (mm)&quot;) +
  theme_bw()</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-18-1.png" width="768" /></p>
<p>Some quick observations:</p>
<ul>
<li>No rainfall in July.</li>
<li>A lot of rain in November!</li>
</ul>
</div>
</div>
<div id="lab-2" class="section level1">
<h1>Lab 2</h1>
<p>In this R Lab, you will be guided by the TA to demonstrate the steps
involved in estimator analysis.</p>
<div id="r-lab-learning-goals-2" class="section level2">
<h2>R Lab Learning Goals</h2>
<ul>
<li>Review and implement the inverse CDF method</li>
<li>Compute a point estimate for an estimator on a sample</li>
<li>Perform a simulation study to investigate the sampling distribution
of an estimator</li>
<li>Learn about R’s <code>apply</code> functions for looping</li>
<li>Use the package <code>gridExtra</code> and the function
<code>grid.arrange</code> to combine plots, and <code>latex2exp</code>
to include relevant details in plot labels</li>
</ul>
</div>
<div id="motivation" class="section level2">
<h2>0. Motivation</h2>
<p>In our work we often find ourselves simulating data from a
probability distributions. R provides built-in functions to simulate
from the most common distributions (e.g. <code>rnorm</code>,
<code>rbinom</code>, etc. ), but we sometimes need to sample from a
distribution that is not included in base R.</p>
<p>Fortunately, the inverse CDF method provides an all-purpose method
for simulating from continuous probability densities, and in the next
section we will demonstrate how it can be used to sample from an
arbitrary continuous density provided we know the CDF and its
inverse.</p>
</div>
<div id="the-inverse-cdf-method" class="section level2">
<h2>1. The inverse CDF method</h2>
<p>Suppose <span class="math inline">\(X\)</span> is a continuous random
variable with distribution function <span
class="math inline">\(F\)</span>. A realization of <span
class="math inline">\(X\)</span> can be simulated as follows:</p>
<ol style="list-style-type: decimal">
<li>Simulate a uniform random variable <span class="math inline">\(U\sim
\text{Uniform(0,1)}\)</span></li>
<li>Assign <span class="math inline">\(X = F^{-1}(U)\)</span></li>
</ol>
<p>To demonstrate this method, consider the following unusual density
function, <span class="math display">\[\begin{equation*}
f(x; \alpha) =
\begin{cases}
\frac{\alpha}{\alpha - 1} \frac{1}{x^2}, &amp; 1 &lt; x \leq \alpha,\\
0 &amp; \text{otherwise}
\end{cases}
\end{equation*}\]</span> This density is definitely not included in R,
so its a perfect opportunity to use the inverse CDF method!</p>
<div id="mathematical-expressions" class="section level3">
<h3>Mathematical expressions</h3>
<p>The first step will be to find the distribution function <span
class="math inline">\(F\)</span>. By integration we find that <span
class="math display">\[\begin{equation*}
F(x) =
\begin{cases}
0 &amp; x \leq 1 \\
\frac{\alpha}{\alpha - 1}\left(1 - \frac{1}{x}\right) &amp; 1 &lt; x
\leq \alpha \\
1 &amp; \alpha &lt; x.
\end{cases}
\end{equation*}\]</span> Next we find the inverse CDF by setting <span
class="math inline">\(u = F(x)\)</span>, <span class="math inline">\((u
\in [0,1])\)</span>, and solving for <span
class="math inline">\(x\)</span>: <span
class="math display">\[\begin{equation*}
F^{-1}(u) =  \left[1 - \frac{\alpha - 1}{\alpha}u\right]^{-1}, \quad (u
\in [0,1]).
\end{equation*}\]</span></p>
</div>
<div id="implementing-method" class="section level3">
<h3>Implementing Method</h3>
<p>With these expressions we can now program a function
<code>rdens</code> to sample from the linear density <span
class="math inline">\(f\)</span> using the inverse CDF method.</p>
<pre class="r"><code># Define the inverse CDF
F_inv &lt;- function(u, a){
  (1-((a-1)/a)*u)^(-1)
}

# Define a function that performs the sampling
rdens &lt;- function(n,a){
  u &lt;- runif(n) # u &lt;- runif(n = n, min = 0, max = 1)
  x &lt;- F_inv(u, a)
  return(x)
}</code></pre>
<p>It is important to verify that our function <code>rdens</code>
behaves as expected. To check our function, we’ll plot a few samples of
size <span class="math inline">\(n = 5000\)</span> from the function to
make sure the density looks correct.</p>
<pre class="r"><code>library(tidyverse)
library(latex2exp)

# Plot the result
data.frame(x = rdens(n = 5000, a = 10)) %&gt;%
  ggplot(aes(x = x, y = ..density..)) +
  geom_histogram(binwidth = 0.2, center = 0.1) + 
  ggtitle(label = TeX(r&#39;(A sample from $f(x)$)&#39;), 
          subtitle = TeX(r&#39;($n = 5000, \alpha = 10$)&#39;)) +
  theme_bw()</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="constructing-an-estimator" class="section level2">
<h2>2. Constructing an Estimator</h2>
<p>Now that we can sample from our distribution, we might be interested
in the behaviour of certain estimators. Suppose we wish to estimate the
parameter <span class="math inline">\(\alpha\)</span> using a sample
from the distribution. Since <span class="math inline">\(\alpha\)</span>
controls the width of the distribution, we might try estimating it using
the maximum value of our sample. By the expression for the density, we
define our estimator to be <span class="math display">\[
\hat \alpha = \max(X_1,...,X_n)
\]</span> It is easy to compute this estimate for each sample we
generate using <code>rdens</code>. All that is needed is to evaluate
<code>max</code> on each sample. For generalizability, we will write a
wrapper function <code>get_ahat</code>.</p>
<pre class="r"><code># Write wrapper function
get_ahat &lt;- function(x){max(x)}

# Evaluate the estimator on a sample
ahat &lt;- get_ahat(rdens(n = 100, a = 10))
cat(ahat)</code></pre>
<pre><code>## 9.0586</code></pre>
<p>By re-running the above chunk we see that there is substantial
variation in the results and the estimates never quite reach the true
value of <span class="math inline">\(10\)</span>. Thus it appears that
our estimator is biased downwards, however it is not easy to calculate
this bias due to the form of the estimator. In these cases, we typically
turn to simulation methods to examine the estimator.</p>
</div>
<div id="bias-of-the-estimator" class="section level2">
<h2>3. Bias of the Estimator</h2>
<p>In this section, we will construct a simulation study to estimate the
bias of the estimator when the sample size is <span
class="math inline">\(n = 100\)</span> and the true value of the
parameter is <span class="math inline">\(\alpha = 10\)</span>. To do
this, we will simulate 1000 independent samples of size 100 from the
density and compute the estimate on each of the samples. From this we
will obtain a sample from the sampling distribution of the estimator,
which we can then use to estimate the bias and other quantities.</p>
<pre class="r"><code># Simulate 1000 datasets of size 100
sim &lt;- replicate(n = 1000, rdens(n = 100, a = 10))
str(sim)</code></pre>
<pre><code>##  num [1:100, 1:1000] 6.73 4.05 8.97 1.18 1.22 ...</code></pre>
<pre class="r"><code># For each sample (each column), compute the statistic
ahat &lt;- apply(sim, MARGIN = 2, FUN = get_ahat)
str(ahat)</code></pre>
<pre><code>##  num [1:1000] 8.97 9.85 9.94 9.58 9.81 ...</code></pre>
<p>Now that we have a sample of size <span
class="math inline">\(1000\)</span> from the sampling distribution of
<span class="math inline">\(\hat\alpha\)</span>, we plot it to learn
more about the distribution</p>
<pre class="r"><code># Plot the sampling distribution of the estimator
data.frame(ahat) %&gt;%
  ggplot(aes(x = ahat, y = ..density..)) +
  geom_histogram(binwidth = 0.2, center = 0.1) +
  ggtitle(
    label = TeX(r&#39;(Sampling distribution for $\hat{\alpha}$)&#39;),
    subtitle = TeX(r&#39;($n = 100, \alpha = 10$, (1000 replications))&#39;)) +
  xlab(TeX(r&#39;($\hat{\alpha}$)&#39;)) +
  theme_bw()</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>From the above sampling distribution, we get a better idea of its
sampling variation, bias, as well as any skewness of the distribution
which is difficult to determine from numeric summaries alone. To get a
more precise estimate of the bias, we simply compute the mean of the
sampling distribution and subtract it from the true value <span
class="math inline">\(\alpha = 10\)</span>.</p>
<pre class="r"><code># Estimated bias of the estimator
bias &lt;- mean(ahat) - 10
cat(bias)</code></pre>
<pre><code>## -0.7583627</code></pre>
<pre class="r"><code># 95% credible interval
ci &lt;- quantile(ahat, probs = c(0.025, 0.975))
cat(ci)</code></pre>
<pre><code>## 7.556135 9.975918</code></pre>
</div>
<div id="consistency-of-the-estimator" class="section level2">
<h2>4. Consistency of the Estimator</h2>
<p>A natural question once we have an estimator is whether or not it is
consistent, that is, as the sample size increases does the estimator
converge in probability to the true value. Once again, this is typically
difficult to prove analytically, so we might satisfy ourselves by
examining the behaviour of the estimator via a simulation study. To do
this, we simulate the sampling distribution of the estimator for sample
sizes of <span class="math inline">\(n = 50\)</span>, <span
class="math inline">\(100\)</span>, <span
class="math inline">\(500\)</span>, and <span
class="math inline">\(1000\)</span> and plot the distributions.</p>
<pre class="r"><code># Function for simulations
sim_study &lt;- function(B, n, a){
  # Simulate B samples of size n
  sim &lt;- replicate(n = B, rdens(n = n, a = a))
  ahat &lt;- apply(sim, MARGIN = 2, FUN = get_ahat)
  
  # Compute bias
  bias &lt;- mean(ahat) - a
  
  # Plot
  fig &lt;- data.frame(ahat) %&gt;%
  ggplot(aes(x = ahat, y = ..density..)) +
  geom_histogram(binwidth = 0.2, center = 0.1) +
  scale_x_continuous(limits = c(5,10)) +
  ggtitle(paste0(&quot;n =&quot;, n)) +
  xlab(TeX(r&#39;($\hat{\alpha}$)&#39;)) +
  theme_bw()
  
  return(list(fig = fig, bias = bias))
}

# Set parameters of simulation study
a &lt;- 10
B &lt;- 1000
n &lt;- c(50, 100, 500, 1000)

# Set seed for reproducibility
set.seed(324)

# Run simulation for each value in n
result &lt;- lapply(n, function(n) sim_study(B = B, n = n, a = a))
names(result) &lt;- paste0(&quot;n_&quot;, n)</code></pre>
<pre class="r"><code># Plot all four plots on a grid using grid.arrange
library(gridExtra)
grid.arrange(result$n_50$fig,
             result$n_100$fig,
             result$n_500$fig,
             result$n_1000$fig)</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-27-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>From the above plots, what can you say about the estimator as the
sample size increases? Does it appear consistent? Is the bias shrinking?
How else does the distribution change?</p>
<p>We can also see our numeric estimates of the bias as follows:</p>
<pre class="r"><code># Print the bias in a data.frame
bias &lt;- lapply(result, function(x) x$bias) %&gt;% as.data.frame()
bias</code></pre>
<pre><code>##        n_50      n_100      n_500      n_1000
## 1 -1.311561 -0.7815966 -0.1703174 -0.09099329</code></pre>
</div>
</div>
<div id="lab-3" class="section level1">
<h1>Lab 3</h1>
<p>In this R Lab, you will be guided by your TA through a second example
of constructing empirical bootstrapped confidence intervals (like we did
in class this week). You will also learn how to produce your own Normal
QQ plots as a means of verifying normality of data.</p>
<div id="r-lab-learning-goals-3" class="section level2">
<h2>R Lab Learning Goals</h2>
<ul>
<li>Review how to read in data and check for missing values</li>
<li>Review steps to construct a confidence interval via empirical
bootstrapping</li>
<li>Learn how to produce a normal QQ plot to check for evidence of
non-normality (violations in normality)</li>
<li>Implement empirical bootstrap and construct your own <span
class="math inline">\(95\%\)</span> bootstrap confidence interval</li>
<li>Interpret the interval constructed</li>
</ul>
</div>
<div id="motivation-1" class="section level2">
<h2>0. Motivation</h2>
<p>In this lab we will be considering laboratory values associated with
diagnosing Type 2 diabetes, specifically glycated hemoglobin (A1C).
Diabetes mellitus is one of the leading causes of death in the United
States and estimating population-level prevalence is therefore an area
of interest in public health research. This data is a subset of <a
href="https://www.cdc.gov/nchs/nhanes/index.htm">The Nation’s Mobile
Health Survey (NHANES)</a> survey for 2017-2018.</p>
</div>
<div id="formulate-a-research-question" class="section level2">
<h2>1. Formulate a research question</h2>
<p>In this presentation we will be considering the following research
question:</p>
<p><em>“What is the average value of A1C in the U.S. population in the
period 2017-2018?”</em></p>
<p>Investigating this question provides us with a crude index for the
prevalence of diabetes in the U.S. population.</p>
<p>Since our inferences are based on a small sample from the whole
population, we will want to quantify the uncertainty in our estimates
due to sampling variation. To this end, we will construct confidence
intervals for our estimates using a bootstrap approach.</p>
</div>
<div id="data-preparation" class="section level2">
<h2>2. Data preparation</h2>
<p>The first task is to load the NHANES data into memory using the
function <code>read.csv</code>.</p>
<pre class="r"><code>library(tidyverse)
library(latex2exp)

# Load the Data:
# It may be helpful to manually set your working directory using `setwd`
setwd(&quot;~/GitHub/dang-kevin.github.io/STA238&quot;)
diabetes &lt;- read.csv(&quot;diabetes.csv&quot;)

# Get a summary of the variables in the nhanes data
# str(diabetes)
glimpse(diabetes)</code></pre>
<pre><code>## Rows: 135
## Columns: 3
## $ seqn &lt;int&gt; 100934, 99455, 99224, 99184, 97031, 98571, 96236, 101113, 95690, 102726, 94994, 101064, 94804, 98358, 95054, 99477, 101612, 100377, 101096, 99024, 94516, 102922…
## $ gh   &lt;dbl&gt; 4.8, 5.2, 5.4, 5.6, 5.2, 5.0, 8.3, 5.8, 7.4, 4.9, 4.9, 5.4, 5.4, 5.9, 4.9, 5.6, 5.7, 5.5, 5.8, 5.0, 5.4, NA, 5.1, 5.7, 6.0, NA, 5.1, 5.7, 5.3, 5.6, NA, 5.0, 9.5…
## $ fpg  &lt;int&gt; 79, 108, 103, 103, 98, 88, 107, 98, 106, 106, 90, 103, 101, 104, 112, 123, 96, 97, 109, 94, 88, NA, 92, 102, 108, NA, 97, 139, 96, 93, NA, 104, 234, 97, 164, 87…</code></pre>
<p>In the above printout, <code>seqn</code> is a subject ID number in
the database, <code>gh</code> is the percentage of glycated hemoglobin
(A1C), and <code>fpg</code> is fasting plasma glucose in mm/dL. The
latter two variables are lab measurements used for diagnosing Type II
diabetes, though our focus in the presentation portion of the lab will
be on the A1C values in <code>gh</code>.</p>
<p>Before we get started on the analysis proper, it is a good idea to
account for any missing values in the data.</p>
<pre class="r"><code># Print a summary of `gh` to check for missing data
summary(diabetes)</code></pre>
<pre><code>##       seqn              gh              fpg       
##  Min.   : 93732   Min.   : 4.600   Min.   : 74.0  
##  1st Qu.: 96355   1st Qu.: 5.275   1st Qu.: 95.0  
##  Median : 99289   Median : 5.500   Median :103.0  
##  Mean   : 98779   Mean   : 5.791   Mean   :111.9  
##  3rd Qu.:101137   3rd Qu.: 5.800   3rd Qu.:112.0  
##  Max.   :102935   Max.   :10.900   Max.   :313.0  
##                   NA&#39;s   :11       NA&#39;s   :11</code></pre>
<p>We see from the summary printout that there are 11 missing values.
For the purposes of this lab we simply note this fact and remove them
from the data.</p>
<pre class="r"><code># For this analysis, we remove missing values 
# You learned other methods of doing this in R Lab #1

diabetes &lt;- diabetes[complete.cases(diabetes),]

# diabetes &lt;- na.omit(diabetes)</code></pre>
</div>
<div id="a-point-estimate" class="section level2">
<h2>3. A point estimate</h2>
<p>Recall that our goal is to estimate the mean A1C of the U.S.
population from 2017-2018.</p>
<p>The estimate based on our sample is:</p>
<pre class="r"><code># Compute the mean A1C in our sample
x_bar &lt;- mean(diabetes$gh)
x_bar</code></pre>
<pre><code>## [1] 5.791129</code></pre>
<p>We would, however, like to include a confidence interval for this
estimate to reflect the uncertainty in our estimate due to sampling
variability. In the next sections we will demonstrate how we will use a
bootstrap approach to construct this confidence interval.</p>
</div>
<div id="bootstrap-confidence-intervals" class="section level2">
<h2>4. Bootstrap confidence intervals</h2>
<p>The first component of any bootstrap approach is deciding how the
bootstrapped datasets will be simulated; will we use a parametric or
empirical approach? To help us decide, we should first examine the
distribution of our data to see if it resembles a parametric density or
not.</p>
<pre class="r"><code># Histogram of `gh`
diabetes %&gt;% 
  ggplot(aes(x = gh)) +
  geom_histogram(aes(y=..density..), 
                 binwidth = 0.2,
                 fill = &#39;thistle2&#39;,
                 colour = &#39;black&#39;) +
  labs(title = &quot;Sample distribution of A1C&quot;,
       x = &quot;A1C&quot;,
       y = &quot;Density&quot;)</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-33-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>On inspection, this distribution looks like it is positively-skewed,
and that a parametric bootstrap based on a normal sampling distribution
is inappropriate. To get a closer look, we can plot the quantiles of the
sample against a normal distribution in a Q-Q plot.</p>
<pre class="r"><code># QQ-plot to assess normality of `gh`
diabetes %&gt;% 
  ggplot(aes(sample = gh)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = &quot;Normal Q-Q plot&quot;,
       subtitle = &quot;Data: A1C&quot;,
       x = TeX(r&#39;($N(0,1)$ Quantiles)&#39;),
       y = &quot;A1C Quantiles&quot;)</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-34-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The Q-Q plot confirms our suspicions that the data in non-normally
distributed. Indeed, about 16% of A1C values reside in the heavy tails
of the sample. (To see this, note that the points that leave the normal
line fall above the <span class="math inline">\(N(0,1)\)</span> quantile
value of <span class="math inline">\(Z \approx 1\)</span>, which
corresponds to <span class="math inline">\(P(Z \geq 1) \approx
0.16\)</span>.)</p>
<p>Because of this non-normality, we opt for an empirical bootstrap
approach to construct confidence intervals for the mean A1C.</p>
</div>
<div id="simulation" class="section level2">
<h2>5. Simulation</h2>
<p>To construct the confidence intervals, we will used what is called
<em>studentized bootstrap confidence intervals</em>. This involves
computing the studentized mean <span class="math display">\[
t^* = \frac{\bar x_n^* - \bar x_n}{s^*_n/\sqrt n}
\]</span> for each bootstrap sample, where <span
class="math inline">\(\bar x_n^*\)</span> and <span
class="math inline">\(s^*_n\)</span> are the bootstrap mean and standard
deviation, respectively, and <span class="math inline">\(\bar
x_n\)</span> is the sample mean of the original data. The confidence
interval for the population mean <span
class="math inline">\(\mu\)</span> is then <span class="math display">\[
\left(\bar x_n - c_u^*\frac{s_n}{\sqrt{n}}, \bar x_n -
c_l^*\frac{s_n}{\sqrt{n}}\right),
\]</span> where <span class="math inline">\(c_l^*\)</span> and <span
class="math inline">\(c_u^*\)</span> are the lower and upper critical
values of the sampling distribution of <span
class="math inline">\(t^*\)</span> that give the desired significance
level. In this lab, we will construct a <span
class="math inline">\(95\%\)</span> confidence interval by taking <span
class="math inline">\(c_l^*\)</span> and <span
class="math inline">\(c_u^*\)</span> to be the <span
class="math inline">\(2.5\%\)</span> and <span
class="math inline">\(97.5\%\)</span> quantiles of the sampling
distribution, respectively.</p>
<pre class="r"><code>## Using For-Loop

# Define the required inputs:
mean.sample &lt;- mean(diabetes$gh) # sample mean of original data
sd.sample &lt;- sd(diabetes$gh) #sample sd of original data
B &lt;-  2000
n.sample &lt;- length(diabetes$gh)
sim.t &lt;- c() #empty vector to store studentized means

## Bootstrapping Step ##
for (i in 1:B){
  boot.sample &lt;- sample(diabetes$gh, n.sample, replace = T)
  boot.mean &lt;- mean(boot.sample)
  boot.sd &lt;- sd(boot.sample)
  
  # Compute studentized mean and store it into sim.t
  sim.t[i] &lt;- (boot.mean-x_bar)/(boot.sd/sqrt(n.sample))
}

## Find the Critical Values ##
(crit.t &lt;- quantile(sim.t, probs = c(0.975, 0.025)))</code></pre>
<pre><code>##     97.5%      2.5% 
##  1.676319 -2.351053</code></pre>
<pre class="r"><code># Compute Bootstrapped CI 
(ci.student &lt;- mean.sample - crit.t*sd.sample/sqrt(n.sample))</code></pre>
<pre><code>##    97.5%     2.5% 
## 5.639214 6.004191</code></pre>
<p>Since we know that if we performed this analysis many times on new
samples of people, the true population mean A1C would be contained in
any interval calculated in the above method in <span
class="math inline">\(95\%\)</span> of replications, this allows us to
interpret the calculated interval: We can say that based on our data, we
are 95% confident that the average A1C in the population could be as low
as 5.6392143 to as high as 6.0041909. (The interpretation of confidence
intervals can be tricky!)</p>
</div>
</div>
<div id="lab-4" class="section level1">
<h1>Lab 4</h1>
<p>In this R Lab, you will be guided by your TA on how to adapt
bootstrapping and simulation to construct confidence intervals and
perform hypothesis tests on two-sample data when normality assumptions
fail. At this point, it is assumed that you will have decent familiarity
in creating histograms using <code>ggplot</code> to assess distribution
shape.</p>
<div id="r-lab-learning-goals-4" class="section level2">
<h2>R Lab Learning Goals</h2>
<ul>
<li>Review: Using <code>filter</code> in <code>dplyr</code> (a package
already contained in <code>tidyverse</code>) to filter data in dataframe
according to some criteria.</li>
<li>Review: Using histograms to gauge normality, and a visual check on
equal-variance assumption.</li>
<li>Use empirical bootstrap to generate confidence intervals for the
difference in population means (for simplicity, you will use the
percentile method instead of the studentized method).</li>
<li>Use permutation test to test for equal population means under
assumptions of equal variance.</li>
</ul>
</div>
<div id="motivation-2" class="section level2">
<h2>0. Motivation</h2>
<p>The data we will be working with today is from a study reported in
<em>A Longitudinal Study of the Development of Elementary School
Children’s Private Speech</em>. In this study, researchers recorded
instances where children were engaged in private speech during a
randomly chosen 10 second interval. Private speech refers to speech
spoken aloud that is either addressed to oneself or to no particular
listener. Many such intervals were observed for <strong>each</strong>
child, and the percentage of intervals where private speech occurred for
each child was recorded. One of the outcomes of interest for this study
and the focus of our tutorial is the following research question:</p>
<p><em>Does the amount of private speech differ between boys and
girls?</em></p>
<p>To put this question into a mathematical context, let <span
class="math inline">\((X_1,...X_m)\)</span> and <span
class="math inline">\((Y_1,...,Y_n)\)</span> denote the percentage of
private speech observed for boys and girls, respectively. Furthermore,
assume that each observation <span class="math inline">\(X_i\)</span>
comes from a population with mean <span
class="math inline">\(\mu_1\)</span> and <span
class="math inline">\(Y_j\)</span> from a population with mean <span
class="math inline">\(\mu_2\)</span>. This problem can then be viewed as
that of making inferences about differences in means <span
class="math inline">\(\mu_1 - \mu_2\)</span>, or determining whether
boys and girls have different engagements in private speech.</p>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2>1. Exploratory data analysis</h2>
<p>To begin exploring this question, let us first load in the study data
and the relevant libraries for our analysis.</p>
<pre class="r"><code>library(tidyverse)
library(latex2exp)
library(gridExtra)

# Load in the speech data
# Remember to set your working directory and ensure data files are stored
# in the same location
setwd(&quot;~/GitHub/dang-kevin.github.io/STA238&quot;)
speech &lt;- read.csv(&quot;speech.csv&quot;)
glimpse(speech)</code></pre>
<pre><code>## Rows: 33
## Columns: 3
## $ X          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33
## $ gender     &lt;chr&gt; &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, …
## $ percentage &lt;dbl&gt; 4.9, 5.5, 6.5, 0.0, 0.0, 3.0, 2.8, 6.4, 1.0, 0.9, 0.0, 28.1, 8.7, 1.6, 5.1, 17.0, 4.7, 28.1, 0.0, 1.3, 2.2, 0.0, 1.3, 0.0, 0.0, 0.0, 0.0, 3.9, 0.0, 10.1, …</code></pre>
<p>Next we will plot the data for boys and girls separately to get an
idea of their distribution. For the purposes of this analysis, the
labels boy and girl refer to a child being labeled as male or female in
the data set.</p>
<pre class="r"><code>###########################################
### Remove the eval=F from the R chunk! ###
###########################################


# Plot the samples for boys and girls using gridExtra
# Density histograms to compare the density histogram of the two samples
plot.boys &lt;- speech %&gt;% 
  filter(gender == &quot;male&quot;) %&gt;% 
  ggplot(aes(x = percentage, y =..density..)) + #density histogram
  geom_histogram(binwidth = 0.5, center = 0.25, #bin aesthetics
                 color = &quot;black&quot;,
                 fill = &quot;thistle2&quot;) +
  labs(title = &quot;Private speech: Boys&quot;,
       x = &quot;Percentage&quot;,
       y = &quot;Density&quot;) +
  xlim(c(0,30)) #common range

plot.girls &lt;- speech %&gt;% 
  filter(gender == &quot;female&quot;) %&gt;% 
  ggplot(aes(x = percentage, y =..density..)) +
  geom_histogram(binwidth = 0.5, center = 0.25,
                 color = &quot;black&quot;,
                 fill =&quot;thistle2&quot;) +
  labs(title = &quot;Private speech: Girls&quot;,
       x = &quot;Percentage&quot;,
       y = &quot;Density&quot;) +
  xlim(c(0,30))

grid.arrange(plot.boys, plot.girls)</code></pre>
<p><img src="STA238_files/figure-html/unnamed-chunk-37-1.png" width="672" style="display: block; margin: auto;" />
From these plots it is clear that the data is not normal and with the
limited data size, any confidence intervals or hypothesis tests based on
the assumption of normality will be misleading. In such situations, we
typically relax the assumption of normal data and turn to non-parametric
approaches to form inferences about the quantities of interest.</p>
<p>In the following sections, we will demonstrate how confidence
intervals can be obtained using a bootstrap approach and how the
so-called permutation test can be used to perform hypothesis testing
with minimal distributional assumptions.</p>
</div>
<div id="bootstrap-confidence-interval-for-the-difference-in-means"
class="section level2">
<h2>2. Bootstrap confidence interval for the difference in means</h2>
<p>In this first section we will demonstrate how to construct a
confidence interval for the difference in means <span
class="math inline">\(\mu_1 - \mu_2\)</span> using a bootstrap approach.
The general approach is very similar to that of the one-sample
problem:</p>
<ul>
<li><p>Draw a bootstrap sample <span
class="math inline">\((X_1^*,...,X_m^*)\)</span> with replacement from
the first group <span
class="math inline">\((X_1,...,X_m)\)</span></p></li>
<li><p>Draw a bootstrap sample <span
class="math inline">\((Y_1^*,...,Y_m^*)\)</span> with replacement from
the second group <span
class="math inline">\((Y_1,...,Y_m)\)</span></p></li>
<li><p>Compute the difference in means <span class="math inline">\(\bar
X^* - \bar Y^*\)</span> for the bootstrap samples</p></li>
<li><p>Repeat this process many times to obtain the bootstrapped
sampling distribution</p></li>
<li><p>Construct a bootstrap confidence interval <span
class="math inline">\((C_{lower}^*, C_{upper}^*)\)</span> from the
sampling distribution.</p></li>
</ul>
<p>In this presentation, we will be using the <strong>percentile
method</strong> to construct the <span
class="math inline">\((1-\alpha)\)</span>-level confidence intervals in
the final step, where <span class="math inline">\(C_{lower}^*\)</span>
and <span class="math inline">\(C_{upper}^*\)</span> are taken to be the
<span class="math inline">\(\alpha/2\)</span> and <span
class="math inline">\(1 - \alpha/2\)</span> sample quantiles of the
bootstrap sampling distribution, respectively. This method is simple,
and makes few assumptions about the shape of the bootstrap sampling
distribution, though the resulting interval is typically biased. To see
another approach similar to the studentized approach from the previous
tutorial, see the discussion in section 10.6 of the textbook.</p>
<div id="implementation-in-r" class="section level3">
<h3>2.1 Implementation in R</h3>
<p>Let’s use this recipe to construct a bootstrapped confidence interval
in R:</p>
<pre class="r"><code>###########################################
### Remove the eval=F from the R chunk! ###
###########################################

# Create vectors containing the observed data for each group

# obs.boys &lt;- speech$percentage[speech$gender == &quot;male&quot;]
# obs.girls &lt;- speech$percentage[speech$gender == &quot;female&quot;]

# Index of data entries that are &quot;male&quot;
index.boys &lt;- speech$gender == &quot;male&quot;

# Percentage entries for the same index that were identified as &quot;male&quot;
obs.boys &lt;- speech$percentage[index.boys] 

# Percentage entries for the indices that are NOT male
obs.girls &lt;- speech$percentage[!index.boys]

# Define the bootstrap experiment
set.seed(431)

B &lt;- 5000
boot.mean.diff &lt;- c()

for(b in 1:B){
  
  # Bootstrap sample for each gender
  boot.boys &lt;- sample(obs.boys, replace = T)
  boot.girls &lt;- sample(obs.girls, replace = T)
  
  # Compute difference in bootstrap means
  boot.mean.diff[b] &lt;- mean(boot.boys) - mean(boot.girls)
  
}</code></pre>
<p>The 95% bootstrap confidence interval for the difference in means is
then</p>
<pre class="r"><code>###########################################
### Remove the eval=F from the R chunk! ###
###########################################

# Compute the 95% percentile confidence interval
ci.mean.diff &lt;- quantile(boot.mean.diff, probs = c(0.025, 0.975))
ci.mean.diff</code></pre>
<pre><code>##     2.5%    97.5% 
## 1.289917 9.473417</code></pre>
<p>The corresponding confidence interval based on the assumption of
normal data can be calculated to be <span class="math inline">\((1.29,
9.47)\)</span>, which has a smaller lower limit compared to our
bootstrapped interval. Given that our data is definitely not normal, we
have more confidence in the validity of the bootstrap-based
interval.</p>
</div>
</div>
<div id="permutation-test-for-hypothesis-testing"
class="section level2">
<h2>3. Permutation test for hypothesis testing</h2>
<p>Another common approach to studying the difference in means between
two groups is the hypothesis testing approach. Here, we consider the
following null and alternative hypotheses:</p>
<ul>
<li><span class="math inline">\(H_0: \quad \mu_1 - \mu_2 =
0\)</span></li>
<li><span class="math inline">\(H_1: \quad \mu_1 - \mu_2 \neq
0\)</span></li>
</ul>
<p>Since our data is not normally distributed, we can no longer use the
two-sample <span class="math inline">\(t-\)</span>test approach, where
the null distribution of the sample statistic is a known <span
class="math inline">\(t-\)</span>distribution.</p>
<div id="the-permutation-test" class="section level3">
<h3>3.1 The permutation test</h3>
<p>If we are comfortable assuming that the <em>only</em> possible
difference in the distribution of the two samples is in their means
<span class="math inline">\(\mu_1, \mu_2\)</span>, then we can use what
is called <strong>the permutation test</strong> to perform this
hypothesis test.</p>
<p>Under the null hypothesis <span class="math inline">\(\mu_1 =
\mu_2\)</span>, where both sampling distributions are the same, every
observation could equally well belong to either group and so the group
labels have no effect on the outcome. Since the group labels are
exchangeable, we can randomly assign them to the observed values and we
will obtain what looks like a new observation from the null distribution
with the same probability as the original sample. By comparing our
observed difference <span class="math inline">\(\bar X - \bar Y\)</span>
to the difference measured on these new permuted data, we can get a
sense of how unlikely it is to observe such a difference under the null
hypothesis.</p>
<p>Following this reasoning, the recipe for the permutation test is as
follows:</p>
<ul>
<li><p>Compute the test statistic <span class="math inline">\(T_{obs} =
\bar X - \bar Y\)</span> on the original data (this test statistic is
labeled T, but does not imply that it has a T-distribution).</p></li>
<li><p>Create a permuted data set by randomly assigning the group labels
to the observed values and compute the test statistic <span
class="math inline">\(T^* = \bar X^* - \bar Y^*\)</span>. </p></li>
<li><p>Repeat this process for every permutation of the data (or a very
large number of permutations)</p></li>
<li><p>Compute <span class="math inline">\(p-\)</span>value of <span
class="math inline">\(T_{obs}\)</span> by computing the proportion of
permuted test statistics <span class="math inline">\(T^*\)</span> that
are at least as “extreme” as <span
class="math inline">\(T_{obs}\)</span>.</p></li>
</ul>
</div>
<div id="implementation-in-r-1" class="section level3">
<h3>3.2 Implementation in R</h3>
<p>We implement the permutation test for our data as follows:</p>
<pre class="r"><code># Compute the observed difference between genders
obs.mean.boys &lt;- mean(speech$percentage[index.boys])
obs.mean.girls &lt;- mean(speech$percentage[!index.boys])
obs.mean.diff &lt;- obs.mean.boys - obs.mean.girls
# obs.mean.diff &lt;- mean(obs.boys) - mean(obs.girls)

# Permutation test
set.seed(134)

B &lt;- 5000
perm.mean.diff &lt;- c()

for(b in 1:B){
  
  # Generate new permutation of data
  perm &lt;- sample(speech$percentage, replace = F)

  # Compute the mean for each group for the permutation
  perm.mean.boys &lt;- mean(perm[index.boys])
  perm.mean.girls &lt;- mean(perm[!index.boys])
  
  # Compute the difference in means for the permutation
  perm.mean.diff[b] &lt;- perm.mean.boys - perm.mean.girls
}</code></pre>
<p>The <span class="math inline">\(p-\)</span>value for the our
particular value of (FILL THIS IN) is then</p>
<pre class="r"><code># Compute p-value
mean(abs(perm.mean.diff) &gt;= abs(obs.mean.diff))</code></pre>
<pre><code>## [1] 0.0302</code></pre>
<p>where we have defined “extreme” to mean <span
class="math inline">\(|T|\geq |T_{obs}|\)</span>, which is a two-tailed
test. Therefore we reject the null hypothesis that <span
class="math inline">\(\mu_1 = \mu_2\)</span> at the <span
class="math inline">\(5\%\)</span> level.</p>
</div>
<div id="note" class="section level3">
<h3>Note</h3>
<p>The assumption that both distributions are the same in every possible
way except perhaps the mean is a very strong assumption that should
typically be checked. In practice we usually require this be
approximately true by checking that the sample variances are roughly
equal. If we check this for our the speech data set, we find that this
is unlikely satisfied and that we may want to use another approach for
testing this hypothesis.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
